{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error ,mean_absolute_error,explained_variance_score,mean_squared_log_error,r2_score,f1_score\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fechamento</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01-2015</th>\n",
       "      <td>314.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02-01-2015</th>\n",
       "      <td>315.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03-01-2015</th>\n",
       "      <td>281.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04-01-2015</th>\n",
       "      <td>264.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-01-2015</th>\n",
       "      <td>274.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fechamento\n",
       "Data                  \n",
       "01-01-2015      314.25\n",
       "02-01-2015      315.03\n",
       "03-01-2015      281.08\n",
       "04-01-2015      264.20\n",
       "05-01-2015      274.47"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Files tcc/data.csv',index_col=['Data'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-250.,    0.,  250.,  500.,  750., 1000., 1250., 1500., 1750.,\n",
       "        2000.]),\n",
       " <a list of 10 Text xticklabel objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot()\n",
    "plt.xticks(rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  314.25],\n",
       "       [  315.03],\n",
       "       [  281.08],\n",
       "       ...,\n",
       "       [10623.54],\n",
       "       [10594.49],\n",
       "       [10575.53]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[['Fechamento']]\n",
    "dataset = df.values\n",
    "dataset = dataset.astype('float32')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145 564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  314.25],\n",
       "       [  315.03],\n",
       "       [  281.08],\n",
       "       ...,\n",
       "       [10233.9 ],\n",
       "       [11112.7 ],\n",
       "       [10551.8 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset)*0.67)\n",
    "teste_size = len(dataset) - train_size\n",
    "train,test = dataset[0:train_size,:],dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "  dataX, dataY = [], []\n",
    "  for i in range(len(dataset)-look_back-1):\n",
    "    a = dataset[i:(i+look_back), 0]\n",
    "    dataX.append(a)\n",
    "    dataY.append(dataset[i + look_back, 0])\n",
    "  return np.array(dataX), np.array(dataY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antes(dataset,look_back=1):\n",
    "    dia_atras = []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        dia_atras.append(dataset[i-1+look_back, 0])\n",
    "    \n",
    "    return np.array(dia_atras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141 1141 560 560 560\n"
     ]
    }
   ],
   "source": [
    "look_back=3\n",
    "trainX, trainY = create_dataset(train, look_back=look_back)\n",
    "testX, testY = create_dataset(test,look_back=look_back)\n",
    "dia_atras = antes(test,look_back=look_back)\n",
    "print(len(trainX),len(trainY),len(testX),len(testY),len(dia_atras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3313: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 140)               560       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 280)               39480     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 280)               78680     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 280)               78680     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 281       \n",
      "=================================================================\n",
      "Total params: 197,681\n",
      "Trainable params: 197,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# ENTRADA :\n",
    "NN_model.add(Dense(140, kernel_initializer='normal',input_dim = trainX.shape[1], activation='relu'))\n",
    "\n",
    "# CAMADA OCULTA :\n",
    "NN_model.add(Dense(280, kernel_initializer='normal',activation='selu'))\n",
    "NN_model.add(Dense(280, kernel_initializer='normal',activation='selu'))\n",
    "NN_model.add(Dense(280, kernel_initializer='normal',activation='selu'))\n",
    "\n",
    "# SAIDA :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('DNN', monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 912 samples, validate on 229 samples\n",
      "Epoch 1/500\n",
      "912/912 [==============================] - 1s 601us/step - loss: 207.6081 - mean_absolute_error: 207.6081 - val_loss: 1528.7549 - val_mean_absolute_error: 1528.7548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1528.75489, saving model to DNN\n",
      "Epoch 2/500\n",
      "912/912 [==============================] - 0s 296us/step - loss: 45.3744 - mean_absolute_error: 45.3744 - val_loss: 897.5921 - val_mean_absolute_error: 897.5921\n",
      "\n",
      "Epoch 00002: val_loss improved from 1528.75489 to 897.59207, saving model to DNN\n",
      "Epoch 3/500\n",
      "912/912 [==============================] - 0s 302us/step - loss: 24.7846 - mean_absolute_error: 24.7846 - val_loss: 482.4726 - val_mean_absolute_error: 482.4726\n",
      "\n",
      "Epoch 00003: val_loss improved from 897.59207 to 482.47261, saving model to DNN\n",
      "Epoch 4/500\n",
      "912/912 [==============================] - 0s 292us/step - loss: 22.6893 - mean_absolute_error: 22.6893 - val_loss: 465.7330 - val_mean_absolute_error: 465.7330\n",
      "\n",
      "Epoch 00004: val_loss improved from 482.47261 to 465.73300, saving model to DNN\n",
      "Epoch 5/500\n",
      "912/912 [==============================] - 0s 295us/step - loss: 23.9865 - mean_absolute_error: 23.9865 - val_loss: 464.6703 - val_mean_absolute_error: 464.6703\n",
      "\n",
      "Epoch 00005: val_loss improved from 465.73300 to 464.67031, saving model to DNN\n",
      "Epoch 6/500\n",
      "912/912 [==============================] - 0s 283us/step - loss: 27.5853 - mean_absolute_error: 27.5853 - val_loss: 597.7403 - val_mean_absolute_error: 597.7402\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 464.67031\n",
      "Epoch 7/500\n",
      "912/912 [==============================] - 0s 289us/step - loss: 25.6270 - mean_absolute_error: 25.6270 - val_loss: 450.9287 - val_mean_absolute_error: 450.9286\n",
      "\n",
      "Epoch 00007: val_loss improved from 464.67031 to 450.92865, saving model to DNN\n",
      "Epoch 8/500\n",
      "912/912 [==============================] - 0s 299us/step - loss: 21.0422 - mean_absolute_error: 21.0422 - val_loss: 527.6773 - val_mean_absolute_error: 527.6772\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 450.92865\n",
      "Epoch 9/500\n",
      "912/912 [==============================] - 0s 284us/step - loss: 20.6687 - mean_absolute_error: 20.6687 - val_loss: 424.0042 - val_mean_absolute_error: 424.0042\n",
      "\n",
      "Epoch 00009: val_loss improved from 450.92865 to 424.00422, saving model to DNN\n",
      "Epoch 10/500\n",
      "912/912 [==============================] - 0s 297us/step - loss: 21.9768 - mean_absolute_error: 21.9768 - val_loss: 418.5059 - val_mean_absolute_error: 418.5059\n",
      "\n",
      "Epoch 00010: val_loss improved from 424.00422 to 418.50588, saving model to DNN\n",
      "Epoch 11/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 17.9270 - mean_absolute_error: 17.9270 - val_loss: 439.3359 - val_mean_absolute_error: 439.3359\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 418.50588\n",
      "Epoch 12/500\n",
      "912/912 [==============================] - 0s 302us/step - loss: 21.3937 - mean_absolute_error: 21.3937 - val_loss: 518.6825 - val_mean_absolute_error: 518.6825\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 418.50588\n",
      "Epoch 13/500\n",
      "912/912 [==============================] - 0s 288us/step - loss: 26.0932 - mean_absolute_error: 26.0932 - val_loss: 415.4885 - val_mean_absolute_error: 415.4885\n",
      "\n",
      "Epoch 00013: val_loss improved from 418.50588 to 415.48849, saving model to DNN\n",
      "Epoch 14/500\n",
      "912/912 [==============================] - 0s 299us/step - loss: 19.9320 - mean_absolute_error: 19.9320 - val_loss: 419.1464 - val_mean_absolute_error: 419.1464\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 415.48849\n",
      "Epoch 15/500\n",
      "912/912 [==============================] - 0s 290us/step - loss: 18.2441 - mean_absolute_error: 18.2441 - val_loss: 435.1396 - val_mean_absolute_error: 435.1396\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 415.48849\n",
      "Epoch 16/500\n",
      "912/912 [==============================] - 0s 288us/step - loss: 19.4158 - mean_absolute_error: 19.4158 - val_loss: 404.6861 - val_mean_absolute_error: 404.6861\n",
      "\n",
      "Epoch 00016: val_loss improved from 415.48849 to 404.68613, saving model to DNN\n",
      "Epoch 17/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 26.1339 - mean_absolute_error: 26.1339 - val_loss: 569.3254 - val_mean_absolute_error: 569.3254\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 404.68613\n",
      "Epoch 18/500\n",
      "912/912 [==============================] - 0s 299us/step - loss: 26.5898 - mean_absolute_error: 26.5898 - val_loss: 447.3269 - val_mean_absolute_error: 447.3269\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 404.68613\n",
      "Epoch 19/500\n",
      "912/912 [==============================] - 0s 288us/step - loss: 28.7206 - mean_absolute_error: 28.7206 - val_loss: 403.0686 - val_mean_absolute_error: 403.0686\n",
      "\n",
      "Epoch 00019: val_loss improved from 404.68613 to 403.06860, saving model to DNN\n",
      "Epoch 20/500\n",
      "912/912 [==============================] - 0s 299us/step - loss: 16.8510 - mean_absolute_error: 16.8510 - val_loss: 394.0506 - val_mean_absolute_error: 394.0506\n",
      "\n",
      "Epoch 00020: val_loss improved from 403.06860 to 394.05062, saving model to DNN\n",
      "Epoch 21/500\n",
      "912/912 [==============================] - 0s 303us/step - loss: 16.9444 - mean_absolute_error: 16.9444 - val_loss: 397.7277 - val_mean_absolute_error: 397.7277\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 394.05062\n",
      "Epoch 22/500\n",
      "912/912 [==============================] - 0s 304us/step - loss: 17.7221 - mean_absolute_error: 17.7221 - val_loss: 391.8066 - val_mean_absolute_error: 391.8066\n",
      "\n",
      "Epoch 00022: val_loss improved from 394.05062 to 391.80662, saving model to DNN\n",
      "Epoch 23/500\n",
      "912/912 [==============================] - 0s 280us/step - loss: 22.9528 - mean_absolute_error: 22.9528 - val_loss: 387.9586 - val_mean_absolute_error: 387.9586\n",
      "\n",
      "Epoch 00023: val_loss improved from 391.80662 to 387.95864, saving model to DNN\n",
      "Epoch 24/500\n",
      "912/912 [==============================] - 0s 341us/step - loss: 21.0047 - mean_absolute_error: 21.0047 - val_loss: 401.8479 - val_mean_absolute_error: 401.8479\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 387.95864\n",
      "Epoch 25/500\n",
      "912/912 [==============================] - 0s 301us/step - loss: 22.2914 - mean_absolute_error: 22.2914 - val_loss: 483.3231 - val_mean_absolute_error: 483.3231\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 387.95864\n",
      "Epoch 26/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 20.8925 - mean_absolute_error: 20.8925 - val_loss: 389.1509 - val_mean_absolute_error: 389.1508\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 387.95864\n",
      "Epoch 27/500\n",
      "912/912 [==============================] - 0s 290us/step - loss: 17.0186 - mean_absolute_error: 17.0186 - val_loss: 382.5008 - val_mean_absolute_error: 382.5008\n",
      "\n",
      "Epoch 00027: val_loss improved from 387.95864 to 382.50075, saving model to DNN\n",
      "Epoch 28/500\n",
      "912/912 [==============================] - 0s 300us/step - loss: 19.4455 - mean_absolute_error: 19.4455 - val_loss: 423.1459 - val_mean_absolute_error: 423.1459\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 382.50075\n",
      "Epoch 29/500\n",
      "912/912 [==============================] - 0s 299us/step - loss: 17.9382 - mean_absolute_error: 17.9382 - val_loss: 385.1682 - val_mean_absolute_error: 385.1682\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 382.50075\n",
      "Epoch 30/500\n",
      "912/912 [==============================] - 0s 317us/step - loss: 26.6851 - mean_absolute_error: 26.6851 - val_loss: 429.0917 - val_mean_absolute_error: 429.0917\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 382.50075\n",
      "Epoch 31/500\n",
      "912/912 [==============================] - 0s 320us/step - loss: 24.9803 - mean_absolute_error: 24.9803 - val_loss: 464.7690 - val_mean_absolute_error: 464.7689\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 382.50075\n",
      "Epoch 32/500\n",
      "912/912 [==============================] - 0s 303us/step - loss: 25.8294 - mean_absolute_error: 25.8294 - val_loss: 387.0676 - val_mean_absolute_error: 387.0676\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 382.50075\n",
      "Epoch 33/500\n",
      "912/912 [==============================] - 0s 303us/step - loss: 17.2062 - mean_absolute_error: 17.2062 - val_loss: 417.0202 - val_mean_absolute_error: 417.0202\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 382.50075\n",
      "Epoch 34/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 17.4813 - mean_absolute_error: 17.4813 - val_loss: 381.8709 - val_mean_absolute_error: 381.8709\n",
      "\n",
      "Epoch 00034: val_loss improved from 382.50075 to 381.87087, saving model to DNN\n",
      "Epoch 35/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 16.1959 - mean_absolute_error: 16.1959 - val_loss: 472.0582 - val_mean_absolute_error: 472.0582\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 381.87087\n",
      "Epoch 36/500\n",
      "912/912 [==============================] - 0s 285us/step - loss: 19.7234 - mean_absolute_error: 19.7234 - val_loss: 394.6756 - val_mean_absolute_error: 394.6755\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 381.87087\n",
      "Epoch 37/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 18.5173 - mean_absolute_error: 18.5173 - val_loss: 415.2761 - val_mean_absolute_error: 415.2761\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 381.87087\n",
      "Epoch 38/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.4048 - mean_absolute_error: 16.4048 - val_loss: 387.8197 - val_mean_absolute_error: 387.8197\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 381.87087\n",
      "Epoch 39/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.5537 - mean_absolute_error: 16.5537 - val_loss: 383.3715 - val_mean_absolute_error: 383.3715\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 381.87087\n",
      "Epoch 40/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 18.3070 - mean_absolute_error: 18.3070 - val_loss: 432.5406 - val_mean_absolute_error: 432.5406\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 381.87087\n",
      "Epoch 41/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 21.5562 - mean_absolute_error: 21.5562 - val_loss: 446.9539 - val_mean_absolute_error: 446.9539\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 381.87087\n",
      "Epoch 42/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 19.3528 - mean_absolute_error: 19.3528 - val_loss: 377.6676 - val_mean_absolute_error: 377.6676\n",
      "\n",
      "Epoch 00042: val_loss improved from 381.87087 to 377.66756, saving model to DNN\n",
      "Epoch 43/500\n",
      "912/912 [==============================] - 0s 295us/step - loss: 16.0776 - mean_absolute_error: 16.0776 - val_loss: 381.6536 - val_mean_absolute_error: 381.6536\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 377.66756\n",
      "Epoch 44/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 18.7791 - mean_absolute_error: 18.7791 - val_loss: 402.4642 - val_mean_absolute_error: 402.4642\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 377.66756\n",
      "Epoch 45/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 21.9390 - mean_absolute_error: 21.9390 - val_loss: 423.6837 - val_mean_absolute_error: 423.6837\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 377.66756\n",
      "Epoch 46/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 19.0577 - mean_absolute_error: 19.0577 - val_loss: 432.5826 - val_mean_absolute_error: 432.5826\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 377.66756\n",
      "Epoch 47/500\n",
      "912/912 [==============================] - 0s 297us/step - loss: 20.1596 - mean_absolute_error: 20.1596 - val_loss: 393.7340 - val_mean_absolute_error: 393.7339\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 377.66756\n",
      "Epoch 48/500\n",
      "912/912 [==============================] - 0s 299us/step - loss: 20.7720 - mean_absolute_error: 20.7720 - val_loss: 452.6764 - val_mean_absolute_error: 452.6765\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 377.66756\n",
      "Epoch 49/500\n",
      "912/912 [==============================] - 0s 349us/step - loss: 19.0415 - mean_absolute_error: 19.0415 - val_loss: 386.1720 - val_mean_absolute_error: 386.1719\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 377.66756\n",
      "Epoch 50/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.9494 - mean_absolute_error: 15.9494 - val_loss: 390.6572 - val_mean_absolute_error: 390.6572\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 377.66756\n",
      "Epoch 51/500\n",
      "912/912 [==============================] - 0s 281us/step - loss: 17.9716 - mean_absolute_error: 17.9716 - val_loss: 476.3672 - val_mean_absolute_error: 476.3672\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 377.66756\n",
      "Epoch 52/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 23.7134 - mean_absolute_error: 23.7134 - val_loss: 431.7065 - val_mean_absolute_error: 431.7065\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 377.66756\n",
      "Epoch 53/500\n",
      "912/912 [==============================] - 0s 284us/step - loss: 21.9892 - mean_absolute_error: 21.9893 - val_loss: 391.3148 - val_mean_absolute_error: 391.3148\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 377.66756\n",
      "Epoch 54/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.4053 - mean_absolute_error: 17.4053 - val_loss: 420.7503 - val_mean_absolute_error: 420.7503\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 377.66756\n",
      "Epoch 55/500\n",
      "912/912 [==============================] - 0s 282us/step - loss: 19.7615 - mean_absolute_error: 19.7615 - val_loss: 377.6668 - val_mean_absolute_error: 377.6668\n",
      "\n",
      "Epoch 00055: val_loss improved from 377.66756 to 377.66684, saving model to DNN\n",
      "Epoch 56/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 17.8373 - mean_absolute_error: 17.8373 - val_loss: 376.3963 - val_mean_absolute_error: 376.3963\n",
      "\n",
      "Epoch 00056: val_loss improved from 377.66684 to 376.39631, saving model to DNN\n",
      "Epoch 57/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.6751 - mean_absolute_error: 16.6751 - val_loss: 453.1587 - val_mean_absolute_error: 453.1587\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 376.39631\n",
      "Epoch 58/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 20.3263 - mean_absolute_error: 20.3263 - val_loss: 376.4016 - val_mean_absolute_error: 376.4016\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 376.39631\n",
      "Epoch 59/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 18.9237 - mean_absolute_error: 18.9237 - val_loss: 376.5874 - val_mean_absolute_error: 376.5875\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 376.39631\n",
      "Epoch 60/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 17.3337 - mean_absolute_error: 17.3337 - val_loss: 376.4877 - val_mean_absolute_error: 376.4878\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 376.39631\n",
      "Epoch 61/500\n",
      "912/912 [==============================] - 0s 262us/step - loss: 16.9736 - mean_absolute_error: 16.9736 - val_loss: 398.5566 - val_mean_absolute_error: 398.5567\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 376.39631\n",
      "Epoch 62/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 16.2000 - mean_absolute_error: 16.2000 - val_loss: 378.6535 - val_mean_absolute_error: 378.6534\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 376.39631\n",
      "Epoch 63/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 16.7581 - mean_absolute_error: 16.7581 - val_loss: 373.7755 - val_mean_absolute_error: 373.7755\n",
      "\n",
      "Epoch 00063: val_loss improved from 376.39631 to 373.77554, saving model to DNN\n",
      "Epoch 64/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.4404 - mean_absolute_error: 17.4404 - val_loss: 374.5939 - val_mean_absolute_error: 374.5939\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 373.77554\n",
      "Epoch 65/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 18.0166 - mean_absolute_error: 18.0166 - val_loss: 373.2711 - val_mean_absolute_error: 373.2711\n",
      "\n",
      "Epoch 00065: val_loss improved from 373.77554 to 373.27105, saving model to DNN\n",
      "Epoch 66/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 18.6156 - mean_absolute_error: 18.6156 - val_loss: 380.0409 - val_mean_absolute_error: 380.0408\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 373.27105\n",
      "Epoch 67/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 19.4349 - mean_absolute_error: 19.4349 - val_loss: 375.7586 - val_mean_absolute_error: 375.7586\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 373.27105\n",
      "Epoch 68/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 16.3156 - mean_absolute_error: 16.3156 - val_loss: 372.5448 - val_mean_absolute_error: 372.5448\n",
      "\n",
      "Epoch 00068: val_loss improved from 373.27105 to 372.54476, saving model to DNN\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 0s 271us/step - loss: 18.2804 - mean_absolute_error: 18.2804 - val_loss: 445.2663 - val_mean_absolute_error: 445.2664\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 372.54476\n",
      "Epoch 70/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 17.2696 - mean_absolute_error: 17.2696 - val_loss: 373.3056 - val_mean_absolute_error: 373.3056\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 372.54476\n",
      "Epoch 71/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 18.5728 - mean_absolute_error: 18.5728 - val_loss: 402.4200 - val_mean_absolute_error: 402.4200\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 372.54476\n",
      "Epoch 72/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 16.5000 - mean_absolute_error: 16.5000 - val_loss: 377.1149 - val_mean_absolute_error: 377.1149\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 372.54476\n",
      "Epoch 73/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 19.3694 - mean_absolute_error: 19.3694 - val_loss: 401.7713 - val_mean_absolute_error: 401.7713\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 372.54476\n",
      "Epoch 74/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 19.2147 - mean_absolute_error: 19.2147 - val_loss: 410.3782 - val_mean_absolute_error: 410.3781\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 372.54476\n",
      "Epoch 75/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 19.6597 - mean_absolute_error: 19.6597 - val_loss: 435.4222 - val_mean_absolute_error: 435.4222\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 372.54476\n",
      "Epoch 76/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 17.1837 - mean_absolute_error: 17.1837 - val_loss: 375.5549 - val_mean_absolute_error: 375.5549\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 372.54476\n",
      "Epoch 77/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 20.5056 - mean_absolute_error: 20.5056 - val_loss: 403.5476 - val_mean_absolute_error: 403.5476\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 372.54476\n",
      "Epoch 78/500\n",
      "912/912 [==============================] - 0s 312us/step - loss: 17.7133 - mean_absolute_error: 17.7133 - val_loss: 394.0720 - val_mean_absolute_error: 394.0720\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 372.54476\n",
      "Epoch 79/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 17.2997 - mean_absolute_error: 17.2997 - val_loss: 394.9521 - val_mean_absolute_error: 394.9521\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 372.54476\n",
      "Epoch 80/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 20.5225 - mean_absolute_error: 20.5225 - val_loss: 442.9440 - val_mean_absolute_error: 442.9439\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 372.54476\n",
      "Epoch 81/500\n",
      "912/912 [==============================] - ETA: 0s - loss: 21.0825 - mean_absolute_error: 21.082 - 0s 270us/step - loss: 19.1382 - mean_absolute_error: 19.1382 - val_loss: 373.3353 - val_mean_absolute_error: 373.3353\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 372.54476\n",
      "Epoch 82/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 17.1240 - mean_absolute_error: 17.1240 - val_loss: 388.4132 - val_mean_absolute_error: 388.4132\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 372.54476\n",
      "Epoch 83/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.0079 - mean_absolute_error: 16.0079 - val_loss: 377.4249 - val_mean_absolute_error: 377.4249\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 372.54476\n",
      "Epoch 84/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.6810 - mean_absolute_error: 17.6810 - val_loss: 374.6103 - val_mean_absolute_error: 374.6103\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 372.54476\n",
      "Epoch 85/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.0425 - mean_absolute_error: 17.0425 - val_loss: 379.4230 - val_mean_absolute_error: 379.4230\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 372.54476\n",
      "Epoch 86/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 30.4419 - mean_absolute_error: 30.4419 - val_loss: 687.3125 - val_mean_absolute_error: 687.3125\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 372.54476\n",
      "Epoch 87/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 27.3675 - mean_absolute_error: 27.3675 - val_loss: 404.7876 - val_mean_absolute_error: 404.7877\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 372.54476\n",
      "Epoch 88/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 19.0456 - mean_absolute_error: 19.0456 - val_loss: 448.0329 - val_mean_absolute_error: 448.0329\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 372.54476\n",
      "Epoch 89/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 19.3249 - mean_absolute_error: 19.3249 - val_loss: 382.9339 - val_mean_absolute_error: 382.9338\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 372.54476\n",
      "Epoch 90/500\n",
      "912/912 [==============================] - 0s 281us/step - loss: 16.1804 - mean_absolute_error: 16.1804 - val_loss: 379.2535 - val_mean_absolute_error: 379.2535\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 372.54476\n",
      "Epoch 91/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 19.4143 - mean_absolute_error: 19.4143 - val_loss: 372.8344 - val_mean_absolute_error: 372.8344\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 372.54476\n",
      "Epoch 92/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 16.0998 - mean_absolute_error: 16.0998 - val_loss: 375.0779 - val_mean_absolute_error: 375.0779\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 372.54476\n",
      "Epoch 93/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.8364 - mean_absolute_error: 16.8364 - val_loss: 438.7631 - val_mean_absolute_error: 438.7631\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 372.54476\n",
      "Epoch 94/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 20.2103 - mean_absolute_error: 20.2103 - val_loss: 430.4280 - val_mean_absolute_error: 430.4279\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 372.54476\n",
      "Epoch 95/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 22.7651 - mean_absolute_error: 22.7651 - val_loss: 397.0637 - val_mean_absolute_error: 397.0637\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 372.54476\n",
      "Epoch 96/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.2611 - mean_absolute_error: 16.2611 - val_loss: 378.2813 - val_mean_absolute_error: 378.2813\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 372.54476\n",
      "Epoch 97/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.8166 - mean_absolute_error: 16.8166 - val_loss: 373.8029 - val_mean_absolute_error: 373.8029\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 372.54476\n",
      "Epoch 98/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.8755 - mean_absolute_error: 15.8755 - val_loss: 373.8759 - val_mean_absolute_error: 373.8759\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 372.54476\n",
      "Epoch 99/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 19.2466 - mean_absolute_error: 19.2466 - val_loss: 397.8827 - val_mean_absolute_error: 397.8827\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 372.54476\n",
      "Epoch 100/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 19.6817 - mean_absolute_error: 19.6817 - val_loss: 377.4979 - val_mean_absolute_error: 377.4979\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 372.54476\n",
      "Epoch 101/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 20.6893 - mean_absolute_error: 20.6893 - val_loss: 457.2217 - val_mean_absolute_error: 457.2216\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 372.54476\n",
      "Epoch 102/500\n",
      "912/912 [==============================] - 0s 297us/step - loss: 20.2582 - mean_absolute_error: 20.2582 - val_loss: 426.5785 - val_mean_absolute_error: 426.5785\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 372.54476\n",
      "Epoch 103/500\n",
      "912/912 [==============================] - 0s 280us/step - loss: 17.7802 - mean_absolute_error: 17.7802 - val_loss: 425.6521 - val_mean_absolute_error: 425.6521\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 372.54476\n",
      "Epoch 104/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 21.2698 - mean_absolute_error: 21.2698 - val_loss: 376.9465 - val_mean_absolute_error: 376.9465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00104: val_loss did not improve from 372.54476\n",
      "Epoch 105/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.8578 - mean_absolute_error: 17.8578 - val_loss: 385.2245 - val_mean_absolute_error: 385.2245\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 372.54476\n",
      "Epoch 106/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 16.8195 - mean_absolute_error: 16.8195 - val_loss: 375.1850 - val_mean_absolute_error: 375.1851\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 372.54476\n",
      "Epoch 107/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 15.9494 - mean_absolute_error: 15.9494 - val_loss: 380.1545 - val_mean_absolute_error: 380.1545\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 372.54476\n",
      "Epoch 108/500\n",
      "912/912 [==============================] - 0s 286us/step - loss: 15.3029 - mean_absolute_error: 15.3029 - val_loss: 398.9947 - val_mean_absolute_error: 398.9948\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 372.54476\n",
      "Epoch 109/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 16.1989 - mean_absolute_error: 16.1989 - val_loss: 391.8580 - val_mean_absolute_error: 391.8580\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 372.54476\n",
      "Epoch 110/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 22.5080 - mean_absolute_error: 22.5080 - val_loss: 484.1666 - val_mean_absolute_error: 484.1666\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 372.54476\n",
      "Epoch 111/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 27.0364 - mean_absolute_error: 27.0364 - val_loss: 438.7737 - val_mean_absolute_error: 438.7737\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 372.54476\n",
      "Epoch 112/500\n",
      "912/912 [==============================] - 0s 291us/step - loss: 18.6614 - mean_absolute_error: 18.6614 - val_loss: 376.5504 - val_mean_absolute_error: 376.5504\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 372.54476\n",
      "Epoch 113/500\n",
      "912/912 [==============================] - 0s 280us/step - loss: 22.3364 - mean_absolute_error: 22.3364 - val_loss: 406.8949 - val_mean_absolute_error: 406.8950\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 372.54476\n",
      "Epoch 114/500\n",
      "912/912 [==============================] - 0s 282us/step - loss: 18.0962 - mean_absolute_error: 18.0962 - val_loss: 374.7241 - val_mean_absolute_error: 374.7241\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 372.54476\n",
      "Epoch 115/500\n",
      "912/912 [==============================] - 0s 317us/step - loss: 18.5595 - mean_absolute_error: 18.5595 - val_loss: 382.9114 - val_mean_absolute_error: 382.9115\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 372.54476\n",
      "Epoch 116/500\n",
      "912/912 [==============================] - 0s 327us/step - loss: 17.8696 - mean_absolute_error: 17.8696 - val_loss: 407.3483 - val_mean_absolute_error: 407.3483\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 372.54476\n",
      "Epoch 117/500\n",
      "912/912 [==============================] - 0s 324us/step - loss: 17.4216 - mean_absolute_error: 17.4216 - val_loss: 506.9803 - val_mean_absolute_error: 506.9803\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 372.54476\n",
      "Epoch 118/500\n",
      "912/912 [==============================] - 0s 315us/step - loss: 16.8320 - mean_absolute_error: 16.8320 - val_loss: 378.6442 - val_mean_absolute_error: 378.6442\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 372.54476\n",
      "Epoch 119/500\n",
      "912/912 [==============================] - 0s 318us/step - loss: 16.8873 - mean_absolute_error: 16.8873 - val_loss: 383.8030 - val_mean_absolute_error: 383.8030\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 372.54476\n",
      "Epoch 120/500\n",
      "912/912 [==============================] - 0s 318us/step - loss: 21.3203 - mean_absolute_error: 21.3203 - val_loss: 472.3417 - val_mean_absolute_error: 472.3417\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 372.54476\n",
      "Epoch 121/500\n",
      "912/912 [==============================] - 0s 322us/step - loss: 25.1184 - mean_absolute_error: 25.1184 - val_loss: 387.7187 - val_mean_absolute_error: 387.7187\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 372.54476\n",
      "Epoch 122/500\n",
      "912/912 [==============================] - 0s 321us/step - loss: 18.9795 - mean_absolute_error: 18.9795 - val_loss: 383.3675 - val_mean_absolute_error: 383.3675\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 372.54476\n",
      "Epoch 123/500\n",
      "912/912 [==============================] - 0s 318us/step - loss: 16.0782 - mean_absolute_error: 16.0782 - val_loss: 377.3211 - val_mean_absolute_error: 377.3211\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 372.54476\n",
      "Epoch 124/500\n",
      "912/912 [==============================] - 0s 319us/step - loss: 18.8812 - mean_absolute_error: 18.8812 - val_loss: 375.6522 - val_mean_absolute_error: 375.6522\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 372.54476\n",
      "Epoch 125/500\n",
      "912/912 [==============================] - 0s 327us/step - loss: 16.0631 - mean_absolute_error: 16.0631 - val_loss: 380.0493 - val_mean_absolute_error: 380.0493\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 372.54476\n",
      "Epoch 126/500\n",
      "912/912 [==============================] - 0s 324us/step - loss: 17.3278 - mean_absolute_error: 17.3278 - val_loss: 387.1307 - val_mean_absolute_error: 387.1307\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 372.54476\n",
      "Epoch 127/500\n",
      "912/912 [==============================] - 0s 332us/step - loss: 19.9490 - mean_absolute_error: 19.9490 - val_loss: 373.5809 - val_mean_absolute_error: 373.5808\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 372.54476\n",
      "Epoch 128/500\n",
      "912/912 [==============================] - 0s 321us/step - loss: 15.7506 - mean_absolute_error: 15.7506 - val_loss: 381.2618 - val_mean_absolute_error: 381.2618\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 372.54476\n",
      "Epoch 129/500\n",
      "912/912 [==============================] - 0s 322us/step - loss: 16.1742 - mean_absolute_error: 16.1742 - val_loss: 374.5898 - val_mean_absolute_error: 374.5898\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 372.54476\n",
      "Epoch 130/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.1412 - mean_absolute_error: 16.1412 - val_loss: 375.6147 - val_mean_absolute_error: 375.6147\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 372.54476\n",
      "Epoch 131/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.1144 - mean_absolute_error: 17.1144 - val_loss: 388.5766 - val_mean_absolute_error: 388.5766\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 372.54476\n",
      "Epoch 132/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 21.6670 - mean_absolute_error: 21.6670 - val_loss: 539.3363 - val_mean_absolute_error: 539.3363\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 372.54476\n",
      "Epoch 133/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 24.2802 - mean_absolute_error: 24.2802 - val_loss: 385.0536 - val_mean_absolute_error: 385.0536\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 372.54476\n",
      "Epoch 134/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 18.1438 - mean_absolute_error: 18.1438 - val_loss: 385.6508 - val_mean_absolute_error: 385.6508\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 372.54476\n",
      "Epoch 135/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 16.7755 - mean_absolute_error: 16.7755 - val_loss: 384.1242 - val_mean_absolute_error: 384.1242\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 372.54476\n",
      "Epoch 136/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.1088 - mean_absolute_error: 17.1088 - val_loss: 413.8315 - val_mean_absolute_error: 413.8315\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 372.54476\n",
      "Epoch 137/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 18.7733 - mean_absolute_error: 18.7733 - val_loss: 398.3337 - val_mean_absolute_error: 398.3337\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 372.54476\n",
      "Epoch 138/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 18.0304 - mean_absolute_error: 18.0304 - val_loss: 406.9322 - val_mean_absolute_error: 406.9322\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 372.54476\n",
      "Epoch 139/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 16.3748 - mean_absolute_error: 16.3748 - val_loss: 382.4624 - val_mean_absolute_error: 382.4624\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 372.54476\n",
      "Epoch 140/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.7640 - mean_absolute_error: 15.7640 - val_loss: 426.1492 - val_mean_absolute_error: 426.1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00140: val_loss did not improve from 372.54476\n",
      "Epoch 141/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 21.7608 - mean_absolute_error: 21.7608 - val_loss: 482.4335 - val_mean_absolute_error: 482.4335\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 372.54476\n",
      "Epoch 142/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 20.3590 - mean_absolute_error: 20.3590 - val_loss: 400.0522 - val_mean_absolute_error: 400.0522\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 372.54476\n",
      "Epoch 143/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 20.8851 - mean_absolute_error: 20.8851 - val_loss: 440.5745 - val_mean_absolute_error: 440.5746\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 372.54476\n",
      "Epoch 144/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 17.8461 - mean_absolute_error: 17.8461 - val_loss: 373.2424 - val_mean_absolute_error: 373.2424\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 372.54476\n",
      "Epoch 145/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 16.2870 - mean_absolute_error: 16.2870 - val_loss: 372.1642 - val_mean_absolute_error: 372.1642\n",
      "\n",
      "Epoch 00145: val_loss improved from 372.54476 to 372.16421, saving model to DNN\n",
      "Epoch 146/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 16.8916 - mean_absolute_error: 16.8916 - val_loss: 389.6435 - val_mean_absolute_error: 389.6435\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 372.16421\n",
      "Epoch 147/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 18.1552 - mean_absolute_error: 18.1552 - val_loss: 489.1306 - val_mean_absolute_error: 489.1306\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 372.16421\n",
      "Epoch 148/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 21.8265 - mean_absolute_error: 21.8265 - val_loss: 375.3094 - val_mean_absolute_error: 375.3094\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 372.16421\n",
      "Epoch 149/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 17.4195 - mean_absolute_error: 17.4195 - val_loss: 385.3865 - val_mean_absolute_error: 385.3865\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 372.16421\n",
      "Epoch 150/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.0546 - mean_absolute_error: 16.0546 - val_loss: 374.9719 - val_mean_absolute_error: 374.9719\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 372.16421\n",
      "Epoch 151/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 15.8567 - mean_absolute_error: 15.8567 - val_loss: 380.6443 - val_mean_absolute_error: 380.6442\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 372.16421\n",
      "Epoch 152/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.5121 - mean_absolute_error: 16.5121 - val_loss: 396.7947 - val_mean_absolute_error: 396.7947\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 372.16421\n",
      "Epoch 153/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 19.0896 - mean_absolute_error: 19.0896 - val_loss: 382.9952 - val_mean_absolute_error: 382.9951\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 372.16421\n",
      "Epoch 154/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 16.5789 - mean_absolute_error: 16.5789 - val_loss: 373.8871 - val_mean_absolute_error: 373.8871\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 372.16421\n",
      "Epoch 155/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 15.6330 - mean_absolute_error: 15.6330 - val_loss: 379.0963 - val_mean_absolute_error: 379.0963\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 372.16421\n",
      "Epoch 156/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 21.0522 - mean_absolute_error: 21.0522 - val_loss: 462.8852 - val_mean_absolute_error: 462.8852\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 372.16421\n",
      "Epoch 157/500\n",
      "912/912 [==============================] - 0s 296us/step - loss: 20.8386 - mean_absolute_error: 20.8386 - val_loss: 379.5908 - val_mean_absolute_error: 379.5908\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 372.16421\n",
      "Epoch 158/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 18.1043 - mean_absolute_error: 18.1043 - val_loss: 442.7500 - val_mean_absolute_error: 442.7500\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 372.16421\n",
      "Epoch 159/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 25.1728 - mean_absolute_error: 25.1728 - val_loss: 398.5050 - val_mean_absolute_error: 398.5050\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 372.16421\n",
      "Epoch 160/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.5399 - mean_absolute_error: 16.5399 - val_loss: 382.9859 - val_mean_absolute_error: 382.9859\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 372.16421\n",
      "Epoch 161/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.4827 - mean_absolute_error: 16.4827 - val_loss: 399.3186 - val_mean_absolute_error: 399.3186\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 372.16421\n",
      "Epoch 162/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.8139 - mean_absolute_error: 15.8139 - val_loss: 413.3940 - val_mean_absolute_error: 413.3941\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 372.16421\n",
      "Epoch 163/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 17.9452 - mean_absolute_error: 17.9452 - val_loss: 383.0520 - val_mean_absolute_error: 383.0520\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 372.16421\n",
      "Epoch 164/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 21.0386 - mean_absolute_error: 21.0386 - val_loss: 431.0192 - val_mean_absolute_error: 431.0192\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 372.16421\n",
      "Epoch 165/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 21.3317 - mean_absolute_error: 21.3317 - val_loss: 386.4004 - val_mean_absolute_error: 386.4004\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 372.16421\n",
      "Epoch 166/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 18.5329 - mean_absolute_error: 18.5329 - val_loss: 392.9763 - val_mean_absolute_error: 392.9763\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 372.16421\n",
      "Epoch 167/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 19.7169 - mean_absolute_error: 19.7169 - val_loss: 381.9277 - val_mean_absolute_error: 381.9276\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 372.16421\n",
      "Epoch 168/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 19.5328 - mean_absolute_error: 19.5328 - val_loss: 372.0654 - val_mean_absolute_error: 372.0654\n",
      "\n",
      "Epoch 00168: val_loss improved from 372.16421 to 372.06544, saving model to DNN\n",
      "Epoch 169/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 17.8541 - mean_absolute_error: 17.8541 - val_loss: 372.2903 - val_mean_absolute_error: 372.2903\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 372.06544\n",
      "Epoch 170/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.3991 - mean_absolute_error: 17.3991 - val_loss: 391.1411 - val_mean_absolute_error: 391.1411\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 372.06544\n",
      "Epoch 171/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 19.8352 - mean_absolute_error: 19.8352 - val_loss: 403.0105 - val_mean_absolute_error: 403.0105\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 372.06544\n",
      "Epoch 172/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 16.4581 - mean_absolute_error: 16.4581 - val_loss: 373.3096 - val_mean_absolute_error: 373.3096\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 372.06544\n",
      "Epoch 173/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 18.0723 - mean_absolute_error: 18.0723 - val_loss: 376.1819 - val_mean_absolute_error: 376.1819\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 372.06544\n",
      "Epoch 174/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 29.2999 - mean_absolute_error: 29.2999 - val_loss: 479.0889 - val_mean_absolute_error: 479.0889\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 372.06544\n",
      "Epoch 175/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 17.8228 - mean_absolute_error: 17.8228 - val_loss: 423.4935 - val_mean_absolute_error: 423.4935\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 372.06544\n",
      "Epoch 176/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 22.5900 - mean_absolute_error: 22.5900 - val_loss: 377.2513 - val_mean_absolute_error: 377.2512\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 372.06544\n",
      "Epoch 177/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.6485 - mean_absolute_error: 16.6485 - val_loss: 420.3169 - val_mean_absolute_error: 420.3169\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 372.06544\n",
      "Epoch 178/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 18.3803 - mean_absolute_error: 18.3803 - val_loss: 376.3280 - val_mean_absolute_error: 376.3280\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 372.06544\n",
      "Epoch 179/500\n",
      "912/912 [==============================] - 0s 261us/step - loss: 16.2809 - mean_absolute_error: 16.2809 - val_loss: 453.1329 - val_mean_absolute_error: 453.1329\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 372.06544\n",
      "Epoch 180/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.3555 - mean_absolute_error: 17.3555 - val_loss: 392.1579 - val_mean_absolute_error: 392.1579\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 372.06544\n",
      "Epoch 181/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.4766 - mean_absolute_error: 15.4766 - val_loss: 372.8152 - val_mean_absolute_error: 372.8152\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 372.06544\n",
      "Epoch 182/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 19.5858 - mean_absolute_error: 19.5858 - val_loss: 415.1026 - val_mean_absolute_error: 415.1026\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 372.06544\n",
      "Epoch 183/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 23.4806 - mean_absolute_error: 23.4806 - val_loss: 484.7572 - val_mean_absolute_error: 484.7572\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 372.06544\n",
      "Epoch 184/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 24.7533 - mean_absolute_error: 24.7533 - val_loss: 384.3969 - val_mean_absolute_error: 384.3969\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 372.06544\n",
      "Epoch 185/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 19.5545 - mean_absolute_error: 19.5545 - val_loss: 374.9033 - val_mean_absolute_error: 374.9033\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 372.06544\n",
      "Epoch 186/500\n",
      "912/912 [==============================] - 0s 275us/step - loss: 16.4350 - mean_absolute_error: 16.4350 - val_loss: 378.6709 - val_mean_absolute_error: 378.6709\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 372.06544\n",
      "Epoch 187/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 15.5084 - mean_absolute_error: 15.5084 - val_loss: 374.4563 - val_mean_absolute_error: 374.4562\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 372.06544\n",
      "Epoch 188/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 18.0073 - mean_absolute_error: 18.0073 - val_loss: 386.1464 - val_mean_absolute_error: 386.1464\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 372.06544\n",
      "Epoch 189/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 17.2954 - mean_absolute_error: 17.2954 - val_loss: 373.3563 - val_mean_absolute_error: 373.3563\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 372.06544\n",
      "Epoch 190/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 15.4715 - mean_absolute_error: 15.4715 - val_loss: 372.4603 - val_mean_absolute_error: 372.4603\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 372.06544\n",
      "Epoch 191/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 17.4913 - mean_absolute_error: 17.4913 - val_loss: 372.7180 - val_mean_absolute_error: 372.7180\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 372.06544\n",
      "Epoch 192/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 15.5400 - mean_absolute_error: 15.5400 - val_loss: 373.5434 - val_mean_absolute_error: 373.5434\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 372.06544\n",
      "Epoch 193/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 16.4247 - mean_absolute_error: 16.4247 - val_loss: 377.8698 - val_mean_absolute_error: 377.8698\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 372.06544\n",
      "Epoch 194/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 17.3115 - mean_absolute_error: 17.3115 - val_loss: 482.6665 - val_mean_absolute_error: 482.6664\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 372.06544\n",
      "Epoch 195/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 23.4389 - mean_absolute_error: 23.4389 - val_loss: 474.1509 - val_mean_absolute_error: 474.1509\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 372.06544\n",
      "Epoch 196/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 17.1601 - mean_absolute_error: 17.1601 - val_loss: 382.1155 - val_mean_absolute_error: 382.1155\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 372.06544\n",
      "Epoch 197/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.3148 - mean_absolute_error: 16.3148 - val_loss: 377.3321 - val_mean_absolute_error: 377.3321\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 372.06544\n",
      "Epoch 198/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.7739 - mean_absolute_error: 16.7739 - val_loss: 372.9202 - val_mean_absolute_error: 372.9202\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 372.06544\n",
      "Epoch 199/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 17.2202 - mean_absolute_error: 17.2202 - val_loss: 383.0188 - val_mean_absolute_error: 383.0188\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 372.06544\n",
      "Epoch 200/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.8271 - mean_absolute_error: 16.8271 - val_loss: 371.8794 - val_mean_absolute_error: 371.8794\n",
      "\n",
      "Epoch 00200: val_loss improved from 372.06544 to 371.87940, saving model to DNN\n",
      "Epoch 201/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 23.0989 - mean_absolute_error: 23.0989 - val_loss: 371.2268 - val_mean_absolute_error: 371.2268\n",
      "\n",
      "Epoch 00201: val_loss improved from 371.87940 to 371.22683, saving model to DNN\n",
      "Epoch 202/500\n",
      "912/912 [==============================] - 0s 262us/step - loss: 19.8721 - mean_absolute_error: 19.8721 - val_loss: 381.2330 - val_mean_absolute_error: 381.2330\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 371.22683\n",
      "Epoch 203/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 16.9122 - mean_absolute_error: 16.9122 - val_loss: 376.4456 - val_mean_absolute_error: 376.4456\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 371.22683\n",
      "Epoch 204/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 23.5375 - mean_absolute_error: 23.5375 - val_loss: 425.5608 - val_mean_absolute_error: 425.5608\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 371.22683\n",
      "Epoch 205/500\n",
      "912/912 [==============================] - 0s 289us/step - loss: 17.2667 - mean_absolute_error: 17.2667 - val_loss: 374.9962 - val_mean_absolute_error: 374.9962\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 371.22683\n",
      "Epoch 206/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 15.0683 - mean_absolute_error: 15.0683 - val_loss: 374.4512 - val_mean_absolute_error: 374.4512\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 371.22683\n",
      "Epoch 207/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 15.2446 - mean_absolute_error: 15.2446 - val_loss: 388.7187 - val_mean_absolute_error: 388.7188\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 371.22683\n",
      "Epoch 208/500\n",
      "912/912 [==============================] - 0s 280us/step - loss: 17.6608 - mean_absolute_error: 17.6608 - val_loss: 383.3697 - val_mean_absolute_error: 383.3697\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 371.22683\n",
      "Epoch 209/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 18.5490 - mean_absolute_error: 18.5490 - val_loss: 382.7114 - val_mean_absolute_error: 382.7114\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 371.22683\n",
      "Epoch 210/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 15.8877 - mean_absolute_error: 15.8877 - val_loss: 428.7114 - val_mean_absolute_error: 428.7114\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 371.22683\n",
      "Epoch 211/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 21.3916 - mean_absolute_error: 21.3916 - val_loss: 377.7785 - val_mean_absolute_error: 377.7784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00211: val_loss did not improve from 371.22683\n",
      "Epoch 212/500\n",
      "912/912 [==============================] - 0s 290us/step - loss: 21.6346 - mean_absolute_error: 21.6346 - val_loss: 387.4909 - val_mean_absolute_error: 387.4908\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 371.22683\n",
      "Epoch 213/500\n",
      "912/912 [==============================] - 0s 318us/step - loss: 17.3530 - mean_absolute_error: 17.3530 - val_loss: 415.3197 - val_mean_absolute_error: 415.3197\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 371.22683\n",
      "Epoch 214/500\n",
      "912/912 [==============================] - 0s 320us/step - loss: 19.9739 - mean_absolute_error: 19.9739 - val_loss: 415.5419 - val_mean_absolute_error: 415.5420\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 371.22683\n",
      "Epoch 215/500\n",
      "912/912 [==============================] - 0s 328us/step - loss: 15.9349 - mean_absolute_error: 15.9349 - val_loss: 372.3785 - val_mean_absolute_error: 372.3785\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 371.22683\n",
      "Epoch 216/500\n",
      "912/912 [==============================] - 0s 322us/step - loss: 16.9394 - mean_absolute_error: 16.9394 - val_loss: 377.3973 - val_mean_absolute_error: 377.3974\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 371.22683\n",
      "Epoch 217/500\n",
      "912/912 [==============================] - 0s 324us/step - loss: 15.1867 - mean_absolute_error: 15.1867 - val_loss: 396.4787 - val_mean_absolute_error: 396.4786\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 371.22683\n",
      "Epoch 218/500\n",
      "912/912 [==============================] - 0s 293us/step - loss: 16.1593 - mean_absolute_error: 16.1593 - val_loss: 376.0358 - val_mean_absolute_error: 376.0358\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 371.22683\n",
      "Epoch 219/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 19.0695 - mean_absolute_error: 19.0695 - val_loss: 382.7353 - val_mean_absolute_error: 382.7353\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 371.22683\n",
      "Epoch 220/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.1767 - mean_absolute_error: 16.1767 - val_loss: 405.7919 - val_mean_absolute_error: 405.7920\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 371.22683\n",
      "Epoch 221/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.4017 - mean_absolute_error: 16.4017 - val_loss: 379.5715 - val_mean_absolute_error: 379.5715\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 371.22683\n",
      "Epoch 222/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 15.9686 - mean_absolute_error: 15.9686 - val_loss: 381.9418 - val_mean_absolute_error: 381.9418\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 371.22683\n",
      "Epoch 223/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.8535 - mean_absolute_error: 16.8535 - val_loss: 378.1862 - val_mean_absolute_error: 378.1861\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 371.22683\n",
      "Epoch 224/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 16.1598 - mean_absolute_error: 16.1598 - val_loss: 372.8786 - val_mean_absolute_error: 372.8785\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 371.22683\n",
      "Epoch 225/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 18.0527 - mean_absolute_error: 18.0527 - val_loss: 405.5423 - val_mean_absolute_error: 405.5423\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 371.22683\n",
      "Epoch 226/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.9806 - mean_absolute_error: 16.9806 - val_loss: 385.5262 - val_mean_absolute_error: 385.5262\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 371.22683\n",
      "Epoch 227/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 16.2802 - mean_absolute_error: 16.2802 - val_loss: 380.4687 - val_mean_absolute_error: 380.4688\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 371.22683\n",
      "Epoch 228/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 17.1677 - mean_absolute_error: 17.1677 - val_loss: 431.4660 - val_mean_absolute_error: 431.4660\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 371.22683\n",
      "Epoch 229/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 16.0146 - mean_absolute_error: 16.0146 - val_loss: 444.1371 - val_mean_absolute_error: 444.1371\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 371.22683\n",
      "Epoch 230/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 18.3043 - mean_absolute_error: 18.3043 - val_loss: 374.0893 - val_mean_absolute_error: 374.0892\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 371.22683\n",
      "Epoch 231/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 17.7231 - mean_absolute_error: 17.7231 - val_loss: 383.2631 - val_mean_absolute_error: 383.2631\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 371.22683\n",
      "Epoch 232/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.9247 - mean_absolute_error: 16.9247 - val_loss: 397.0313 - val_mean_absolute_error: 397.0313\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 371.22683\n",
      "Epoch 233/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 17.8549 - mean_absolute_error: 17.8549 - val_loss: 405.7630 - val_mean_absolute_error: 405.7630\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 371.22683\n",
      "Epoch 234/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 16.1009 - mean_absolute_error: 16.1009 - val_loss: 376.7747 - val_mean_absolute_error: 376.7747\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 371.22683\n",
      "Epoch 235/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 20.5896 - mean_absolute_error: 20.5896 - val_loss: 444.6787 - val_mean_absolute_error: 444.6787\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 371.22683\n",
      "Epoch 236/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 20.9783 - mean_absolute_error: 20.9783 - val_loss: 425.9774 - val_mean_absolute_error: 425.9774\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 371.22683\n",
      "Epoch 237/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 17.5863 - mean_absolute_error: 17.5863 - val_loss: 373.7692 - val_mean_absolute_error: 373.7692\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 371.22683\n",
      "Epoch 238/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 17.3968 - mean_absolute_error: 17.3968 - val_loss: 402.9050 - val_mean_absolute_error: 402.9051\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 371.22683\n",
      "Epoch 239/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 18.9261 - mean_absolute_error: 18.9261 - val_loss: 454.3666 - val_mean_absolute_error: 454.3666\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 371.22683\n",
      "Epoch 240/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 19.9600 - mean_absolute_error: 19.9600 - val_loss: 377.6711 - val_mean_absolute_error: 377.6712\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 371.22683\n",
      "Epoch 241/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 16.4449 - mean_absolute_error: 16.4449 - val_loss: 373.4022 - val_mean_absolute_error: 373.4022\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 371.22683\n",
      "Epoch 242/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 17.1862 - mean_absolute_error: 17.1862 - val_loss: 378.2401 - val_mean_absolute_error: 378.2401\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 371.22683\n",
      "Epoch 243/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.6693 - mean_absolute_error: 15.6693 - val_loss: 386.7522 - val_mean_absolute_error: 386.7522\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 371.22683\n",
      "Epoch 244/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 18.4386 - mean_absolute_error: 18.4386 - val_loss: 377.5205 - val_mean_absolute_error: 377.5205\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 371.22683\n",
      "Epoch 245/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 17.1679 - mean_absolute_error: 17.1679 - val_loss: 378.0042 - val_mean_absolute_error: 378.0042\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 371.22683\n",
      "Epoch 246/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 20.6763 - mean_absolute_error: 20.6763 - val_loss: 420.6012 - val_mean_absolute_error: 420.6012\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 371.22683\n",
      "Epoch 247/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 18.1863 - mean_absolute_error: 18.1863 - val_loss: 384.6185 - val_mean_absolute_error: 384.6184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00247: val_loss did not improve from 371.22683\n",
      "Epoch 248/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 17.0172 - mean_absolute_error: 17.0172 - val_loss: 423.4228 - val_mean_absolute_error: 423.4229\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 371.22683\n",
      "Epoch 249/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 16.9695 - mean_absolute_error: 16.9695 - val_loss: 385.9591 - val_mean_absolute_error: 385.9591\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 371.22683\n",
      "Epoch 250/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.4635 - mean_absolute_error: 15.4635 - val_loss: 373.3537 - val_mean_absolute_error: 373.3537\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 371.22683\n",
      "Epoch 251/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 18.7196 - mean_absolute_error: 18.7196 - val_loss: 386.7508 - val_mean_absolute_error: 386.7508\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 371.22683\n",
      "Epoch 252/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 16.8546 - mean_absolute_error: 16.8546 - val_loss: 390.6837 - val_mean_absolute_error: 390.6837\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 371.22683\n",
      "Epoch 253/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.7979 - mean_absolute_error: 15.7979 - val_loss: 383.2001 - val_mean_absolute_error: 383.2001\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 371.22683\n",
      "Epoch 254/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.5822 - mean_absolute_error: 16.5822 - val_loss: 425.4700 - val_mean_absolute_error: 425.4700\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 371.22683\n",
      "Epoch 255/500\n",
      "912/912 [==============================] - 0s 277us/step - loss: 20.0370 - mean_absolute_error: 20.0370 - val_loss: 387.3059 - val_mean_absolute_error: 387.3059\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 371.22683\n",
      "Epoch 256/500\n",
      "912/912 [==============================] - 0s 261us/step - loss: 15.8979 - mean_absolute_error: 15.8979 - val_loss: 455.9562 - val_mean_absolute_error: 455.9562\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 371.22683\n",
      "Epoch 257/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.6751 - mean_absolute_error: 16.6751 - val_loss: 380.5232 - val_mean_absolute_error: 380.5231\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 371.22683\n",
      "Epoch 258/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 16.0053 - mean_absolute_error: 16.0053 - val_loss: 374.5143 - val_mean_absolute_error: 374.5143\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 371.22683\n",
      "Epoch 259/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 15.7709 - mean_absolute_error: 15.7709 - val_loss: 389.7416 - val_mean_absolute_error: 389.7416\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 371.22683\n",
      "Epoch 260/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 19.1097 - mean_absolute_error: 19.1097 - val_loss: 458.3219 - val_mean_absolute_error: 458.3219\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 371.22683\n",
      "Epoch 261/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 21.1954 - mean_absolute_error: 21.1954 - val_loss: 392.0512 - val_mean_absolute_error: 392.0512\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 371.22683\n",
      "Epoch 262/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 17.7019 - mean_absolute_error: 17.7019 - val_loss: 375.0757 - val_mean_absolute_error: 375.0757\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 371.22683\n",
      "Epoch 263/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 18.6971 - mean_absolute_error: 18.6971 - val_loss: 429.5400 - val_mean_absolute_error: 429.5400\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 371.22683\n",
      "Epoch 264/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 18.9222 - mean_absolute_error: 18.9222 - val_loss: 383.7019 - val_mean_absolute_error: 383.7019\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 371.22683\n",
      "Epoch 265/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 17.3828 - mean_absolute_error: 17.3828 - val_loss: 376.9343 - val_mean_absolute_error: 376.9343\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 371.22683\n",
      "Epoch 266/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 24.2264 - mean_absolute_error: 24.2264 - val_loss: 405.6525 - val_mean_absolute_error: 405.6526\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 371.22683\n",
      "Epoch 267/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 18.2694 - mean_absolute_error: 18.2694 - val_loss: 404.1623 - val_mean_absolute_error: 404.1623\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 371.22683\n",
      "Epoch 268/500\n",
      "912/912 [==============================] - 0s 261us/step - loss: 18.7508 - mean_absolute_error: 18.7508 - val_loss: 397.0998 - val_mean_absolute_error: 397.0998\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 371.22683\n",
      "Epoch 269/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 20.7414 - mean_absolute_error: 20.7414 - val_loss: 379.3710 - val_mean_absolute_error: 379.3710\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 371.22683\n",
      "Epoch 270/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 16.7573 - mean_absolute_error: 16.7573 - val_loss: 389.1951 - val_mean_absolute_error: 389.1951\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 371.22683\n",
      "Epoch 271/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.3306 - mean_absolute_error: 16.3306 - val_loss: 372.9910 - val_mean_absolute_error: 372.9910\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 371.22683\n",
      "Epoch 272/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.4473 - mean_absolute_error: 15.4473 - val_loss: 389.3184 - val_mean_absolute_error: 389.3183\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 371.22683\n",
      "Epoch 273/500\n",
      "912/912 [==============================] - 0s 280us/step - loss: 16.4518 - mean_absolute_error: 16.4518 - val_loss: 384.4587 - val_mean_absolute_error: 384.4586\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 371.22683\n",
      "Epoch 274/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 17.0171 - mean_absolute_error: 17.0171 - val_loss: 377.0804 - val_mean_absolute_error: 377.0804\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 371.22683\n",
      "Epoch 275/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.8284 - mean_absolute_error: 15.8284 - val_loss: 384.1561 - val_mean_absolute_error: 384.1560\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 371.22683\n",
      "Epoch 276/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 15.8857 - mean_absolute_error: 15.8857 - val_loss: 381.6115 - val_mean_absolute_error: 381.6115\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 371.22683\n",
      "Epoch 277/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 17.1539 - mean_absolute_error: 17.1539 - val_loss: 379.7545 - val_mean_absolute_error: 379.7545\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 371.22683\n",
      "Epoch 278/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.4857 - mean_absolute_error: 15.4857 - val_loss: 392.2415 - val_mean_absolute_error: 392.2415\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 371.22683\n",
      "Epoch 279/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 16.2755 - mean_absolute_error: 16.2755 - val_loss: 373.2199 - val_mean_absolute_error: 373.2199\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 371.22683\n",
      "Epoch 280/500\n",
      "912/912 [==============================] - 0s 312us/step - loss: 16.0526 - mean_absolute_error: 16.0526 - val_loss: 399.2846 - val_mean_absolute_error: 399.2846\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 371.22683\n",
      "Epoch 281/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 17.7021 - mean_absolute_error: 17.7021 - val_loss: 405.5868 - val_mean_absolute_error: 405.5868\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 371.22683\n",
      "Epoch 282/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 15.7523 - mean_absolute_error: 15.7523 - val_loss: 373.5319 - val_mean_absolute_error: 373.5319\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 371.22683\n",
      "Epoch 283/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 17.1000 - mean_absolute_error: 17.1000 - val_loss: 379.5014 - val_mean_absolute_error: 379.5013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00283: val_loss did not improve from 371.22683\n",
      "Epoch 284/500\n",
      "912/912 [==============================] - 0s 277us/step - loss: 17.6773 - mean_absolute_error: 17.6773 - val_loss: 380.7934 - val_mean_absolute_error: 380.7934\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 371.22683\n",
      "Epoch 285/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 21.7408 - mean_absolute_error: 21.7408 - val_loss: 381.2647 - val_mean_absolute_error: 381.2647\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 371.22683\n",
      "Epoch 286/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 18.1240 - mean_absolute_error: 18.1240 - val_loss: 378.3726 - val_mean_absolute_error: 378.3726\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 371.22683\n",
      "Epoch 287/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 17.5091 - mean_absolute_error: 17.5091 - val_loss: 408.1583 - val_mean_absolute_error: 408.1583\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 371.22683\n",
      "Epoch 288/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 15.9557 - mean_absolute_error: 15.9557 - val_loss: 388.5308 - val_mean_absolute_error: 388.5308\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 371.22683\n",
      "Epoch 289/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 15.8566 - mean_absolute_error: 15.8566 - val_loss: 397.3867 - val_mean_absolute_error: 397.3867\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 371.22683\n",
      "Epoch 290/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 17.8814 - mean_absolute_error: 17.8814 - val_loss: 374.6591 - val_mean_absolute_error: 374.6591\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 371.22683\n",
      "Epoch 291/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 15.7226 - mean_absolute_error: 15.7226 - val_loss: 401.6973 - val_mean_absolute_error: 401.6973\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 371.22683\n",
      "Epoch 292/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 16.5508 - mean_absolute_error: 16.5508 - val_loss: 374.4907 - val_mean_absolute_error: 374.4907\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 371.22683\n",
      "Epoch 293/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 17.7006 - mean_absolute_error: 17.7006 - val_loss: 451.2261 - val_mean_absolute_error: 451.2262\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 371.22683\n",
      "Epoch 294/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 16.6084 - mean_absolute_error: 16.6084 - val_loss: 375.9519 - val_mean_absolute_error: 375.9519\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 371.22683\n",
      "Epoch 295/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 15.3000 - mean_absolute_error: 15.3000 - val_loss: 403.3313 - val_mean_absolute_error: 403.3313\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 371.22683\n",
      "Epoch 296/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.9748 - mean_absolute_error: 15.9748 - val_loss: 382.2020 - val_mean_absolute_error: 382.2020\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 371.22683\n",
      "Epoch 297/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.8837 - mean_absolute_error: 17.8837 - val_loss: 370.9969 - val_mean_absolute_error: 370.9969\n",
      "\n",
      "Epoch 00297: val_loss improved from 371.22683 to 370.99691, saving model to DNN\n",
      "Epoch 298/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.3351 - mean_absolute_error: 17.3351 - val_loss: 378.7699 - val_mean_absolute_error: 378.7700\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 370.99691\n",
      "Epoch 299/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.1077 - mean_absolute_error: 17.1077 - val_loss: 419.2782 - val_mean_absolute_error: 419.2782\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 370.99691\n",
      "Epoch 300/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 21.2669 - mean_absolute_error: 21.2669 - val_loss: 391.6143 - val_mean_absolute_error: 391.6143\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 370.99691\n",
      "Epoch 301/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.2099 - mean_absolute_error: 16.2099 - val_loss: 373.4639 - val_mean_absolute_error: 373.4639\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 370.99691\n",
      "Epoch 302/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 16.0484 - mean_absolute_error: 16.0484 - val_loss: 405.9061 - val_mean_absolute_error: 405.9062\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 370.99691\n",
      "Epoch 303/500\n",
      "912/912 [==============================] - 0s 331us/step - loss: 20.5126 - mean_absolute_error: 20.5126 - val_loss: 407.5963 - val_mean_absolute_error: 407.5963\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 370.99691\n",
      "Epoch 304/500\n",
      "912/912 [==============================] - 0s 315us/step - loss: 17.5331 - mean_absolute_error: 17.5331 - val_loss: 379.4217 - val_mean_absolute_error: 379.4217\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 370.99691\n",
      "Epoch 305/500\n",
      "912/912 [==============================] - 0s 303us/step - loss: 18.3214 - mean_absolute_error: 18.3214 - val_loss: 385.1549 - val_mean_absolute_error: 385.1550\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 370.99691\n",
      "Epoch 306/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 15.6959 - mean_absolute_error: 15.6959 - val_loss: 395.4562 - val_mean_absolute_error: 395.4563\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 370.99691\n",
      "Epoch 307/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 15.6582 - mean_absolute_error: 15.6582 - val_loss: 375.4035 - val_mean_absolute_error: 375.4035\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 370.99691\n",
      "Epoch 308/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 18.1949 - mean_absolute_error: 18.1949 - val_loss: 421.5303 - val_mean_absolute_error: 421.5303\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 370.99691\n",
      "Epoch 309/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 17.6369 - mean_absolute_error: 17.6369 - val_loss: 478.3338 - val_mean_absolute_error: 478.3338\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 370.99691\n",
      "Epoch 310/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 20.8091 - mean_absolute_error: 20.8091 - val_loss: 372.2774 - val_mean_absolute_error: 372.2774\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 370.99691\n",
      "Epoch 311/500\n",
      "912/912 [==============================] - 0s 280us/step - loss: 16.6313 - mean_absolute_error: 16.6313 - val_loss: 370.3647 - val_mean_absolute_error: 370.3647\n",
      "\n",
      "Epoch 00311: val_loss improved from 370.99691 to 370.36471, saving model to DNN\n",
      "Epoch 312/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.2619 - mean_absolute_error: 16.2619 - val_loss: 372.4733 - val_mean_absolute_error: 372.4734\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 370.36471\n",
      "Epoch 313/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 17.8119 - mean_absolute_error: 17.8119 - val_loss: 378.5809 - val_mean_absolute_error: 378.5808\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 370.36471\n",
      "Epoch 314/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 16.9645 - mean_absolute_error: 16.9645 - val_loss: 377.1985 - val_mean_absolute_error: 377.1985\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 370.36471\n",
      "Epoch 315/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.2963 - mean_absolute_error: 15.2963 - val_loss: 373.7972 - val_mean_absolute_error: 373.7972\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 370.36471\n",
      "Epoch 316/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.3420 - mean_absolute_error: 16.3420 - val_loss: 380.6702 - val_mean_absolute_error: 380.6702\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 370.36471\n",
      "Epoch 317/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 18.2144 - mean_absolute_error: 18.2144 - val_loss: 396.5935 - val_mean_absolute_error: 396.5935\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 370.36471\n",
      "Epoch 318/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 18.5516 - mean_absolute_error: 18.5516 - val_loss: 377.8259 - val_mean_absolute_error: 377.8259\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 370.36471\n",
      "Epoch 319/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 15.5876 - mean_absolute_error: 15.5876 - val_loss: 454.8598 - val_mean_absolute_error: 454.8599\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 370.36471\n",
      "Epoch 320/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 21.1844 - mean_absolute_error: 21.1844 - val_loss: 393.7900 - val_mean_absolute_error: 393.7900\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 370.36471\n",
      "Epoch 321/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 17.0842 - mean_absolute_error: 17.0842 - val_loss: 379.3127 - val_mean_absolute_error: 379.3127\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 370.36471\n",
      "Epoch 322/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 15.4219 - mean_absolute_error: 15.4219 - val_loss: 375.8299 - val_mean_absolute_error: 375.8299\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 370.36471\n",
      "Epoch 323/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 16.7100 - mean_absolute_error: 16.7100 - val_loss: 372.0026 - val_mean_absolute_error: 372.0026\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 370.36471\n",
      "Epoch 324/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.5691 - mean_absolute_error: 15.5691 - val_loss: 371.4727 - val_mean_absolute_error: 371.4727\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 370.36471\n",
      "Epoch 325/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 15.3205 - mean_absolute_error: 15.3205 - val_loss: 374.8202 - val_mean_absolute_error: 374.8202\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 370.36471\n",
      "Epoch 326/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 19.3892 - mean_absolute_error: 19.3892 - val_loss: 374.0954 - val_mean_absolute_error: 374.0954\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 370.36471\n",
      "Epoch 327/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 20.4272 - mean_absolute_error: 20.4272 - val_loss: 403.1335 - val_mean_absolute_error: 403.1335\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 370.36471\n",
      "Epoch 328/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.4847 - mean_absolute_error: 15.4847 - val_loss: 374.9814 - val_mean_absolute_error: 374.9814\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 370.36471\n",
      "Epoch 329/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 21.1904 - mean_absolute_error: 21.1904 - val_loss: 406.8953 - val_mean_absolute_error: 406.8953\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 370.36471\n",
      "Epoch 330/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.1595 - mean_absolute_error: 17.1595 - val_loss: 401.3569 - val_mean_absolute_error: 401.3569\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 370.36471\n",
      "Epoch 331/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 15.6386 - mean_absolute_error: 15.6386 - val_loss: 380.5520 - val_mean_absolute_error: 380.5520\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 370.36471\n",
      "Epoch 332/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.8568 - mean_absolute_error: 16.8568 - val_loss: 372.7659 - val_mean_absolute_error: 372.7659\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 370.36471\n",
      "Epoch 333/500\n",
      "912/912 [==============================] - 0s 281us/step - loss: 17.9828 - mean_absolute_error: 17.9828 - val_loss: 397.5510 - val_mean_absolute_error: 397.5510\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 370.36471\n",
      "Epoch 334/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 15.6700 - mean_absolute_error: 15.6700 - val_loss: 446.2134 - val_mean_absolute_error: 446.2134\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 370.36471\n",
      "Epoch 335/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 19.9319 - mean_absolute_error: 19.9319 - val_loss: 376.2275 - val_mean_absolute_error: 376.2275\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 370.36471\n",
      "Epoch 336/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 17.9349 - mean_absolute_error: 17.9349 - val_loss: 399.2392 - val_mean_absolute_error: 399.2392\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 370.36471\n",
      "Epoch 337/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 17.2908 - mean_absolute_error: 17.2908 - val_loss: 378.3727 - val_mean_absolute_error: 378.3727\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 370.36471\n",
      "Epoch 338/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.7479 - mean_absolute_error: 16.7479 - val_loss: 371.3194 - val_mean_absolute_error: 371.3194\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 370.36471\n",
      "Epoch 339/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 15.9818 - mean_absolute_error: 15.9818 - val_loss: 371.2035 - val_mean_absolute_error: 371.2035\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 370.36471\n",
      "Epoch 340/500\n",
      "912/912 [==============================] - 0s 287us/step - loss: 15.2584 - mean_absolute_error: 15.2584 - val_loss: 377.1315 - val_mean_absolute_error: 377.1314\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 370.36471\n",
      "Epoch 341/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.4738 - mean_absolute_error: 17.4738 - val_loss: 393.7134 - val_mean_absolute_error: 393.7134\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 370.36471\n",
      "Epoch 342/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 22.1705 - mean_absolute_error: 22.1705 - val_loss: 445.7581 - val_mean_absolute_error: 445.7581\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 370.36471\n",
      "Epoch 343/500\n",
      "912/912 [==============================] - 0s 279us/step - loss: 18.2796 - mean_absolute_error: 18.2796 - val_loss: 409.9920 - val_mean_absolute_error: 409.9920\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 370.36471\n",
      "Epoch 344/500\n",
      "912/912 [==============================] - 0s 281us/step - loss: 16.7919 - mean_absolute_error: 16.7919 - val_loss: 376.3108 - val_mean_absolute_error: 376.3108\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 370.36471\n",
      "Epoch 345/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 15.3224 - mean_absolute_error: 15.3224 - val_loss: 373.0942 - val_mean_absolute_error: 373.0941\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 370.36471\n",
      "Epoch 346/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 15.7543 - mean_absolute_error: 15.7543 - val_loss: 371.7870 - val_mean_absolute_error: 371.7870\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 370.36471\n",
      "Epoch 347/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 18.4559 - mean_absolute_error: 18.4559 - val_loss: 382.2698 - val_mean_absolute_error: 382.2698\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 370.36471\n",
      "Epoch 348/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 16.8992 - mean_absolute_error: 16.8992 - val_loss: 398.2468 - val_mean_absolute_error: 398.2468\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 370.36471\n",
      "Epoch 349/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 17.8037 - mean_absolute_error: 17.8037 - val_loss: 400.7251 - val_mean_absolute_error: 400.7251\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 370.36471\n",
      "Epoch 350/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 18.0765 - mean_absolute_error: 18.0765 - val_loss: 407.9556 - val_mean_absolute_error: 407.9556\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 370.36471\n",
      "Epoch 351/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 17.9908 - mean_absolute_error: 17.9908 - val_loss: 411.5950 - val_mean_absolute_error: 411.5950\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 370.36471\n",
      "Epoch 352/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 15.9071 - mean_absolute_error: 15.9071 - val_loss: 373.8368 - val_mean_absolute_error: 373.8368\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 370.36471\n",
      "Epoch 353/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 15.8405 - mean_absolute_error: 15.8405 - val_loss: 373.8066 - val_mean_absolute_error: 373.8066\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 370.36471\n",
      "Epoch 354/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 15.6036 - mean_absolute_error: 15.6036 - val_loss: 372.8898 - val_mean_absolute_error: 372.8898\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 370.36471\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 0s 271us/step - loss: 16.0855 - mean_absolute_error: 16.0855 - val_loss: 373.1532 - val_mean_absolute_error: 373.1532\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 370.36471\n",
      "Epoch 356/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 15.8378 - mean_absolute_error: 15.8378 - val_loss: 372.1270 - val_mean_absolute_error: 372.1270\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 370.36471\n",
      "Epoch 357/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 15.4016 - mean_absolute_error: 15.4016 - val_loss: 380.4541 - val_mean_absolute_error: 380.4542\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 370.36471\n",
      "Epoch 358/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.7706 - mean_absolute_error: 16.7706 - val_loss: 383.4619 - val_mean_absolute_error: 383.4619\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 370.36471\n",
      "Epoch 359/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 15.4343 - mean_absolute_error: 15.4343 - val_loss: 395.7595 - val_mean_absolute_error: 395.7596\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 370.36471\n",
      "Epoch 360/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 16.3933 - mean_absolute_error: 16.3933 - val_loss: 377.3331 - val_mean_absolute_error: 377.3331\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 370.36471\n",
      "Epoch 361/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.2199 - mean_absolute_error: 16.2199 - val_loss: 378.8829 - val_mean_absolute_error: 378.8828\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 370.36471\n",
      "Epoch 362/500\n",
      "912/912 [==============================] - 0s 282us/step - loss: 15.6420 - mean_absolute_error: 15.6420 - val_loss: 373.0433 - val_mean_absolute_error: 373.0433\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 370.36471\n",
      "Epoch 363/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 15.4218 - mean_absolute_error: 15.4218 - val_loss: 390.6537 - val_mean_absolute_error: 390.6537\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 370.36471\n",
      "Epoch 364/500\n",
      "912/912 [==============================] - 0s 287us/step - loss: 16.5927 - mean_absolute_error: 16.5927 - val_loss: 378.3878 - val_mean_absolute_error: 378.3878\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 370.36471\n",
      "Epoch 365/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.9191 - mean_absolute_error: 15.9191 - val_loss: 393.9121 - val_mean_absolute_error: 393.9120\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 370.36471\n",
      "Epoch 366/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 16.4383 - mean_absolute_error: 16.4383 - val_loss: 371.1074 - val_mean_absolute_error: 371.1074\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 370.36471\n",
      "Epoch 367/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 15.3840 - mean_absolute_error: 15.3840 - val_loss: 372.5237 - val_mean_absolute_error: 372.5237\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 370.36471\n",
      "Epoch 368/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.1911 - mean_absolute_error: 15.1911 - val_loss: 405.5112 - val_mean_absolute_error: 405.5112\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 370.36471\n",
      "Epoch 369/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 20.0202 - mean_absolute_error: 20.0203 - val_loss: 427.0598 - val_mean_absolute_error: 427.0598\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 370.36471\n",
      "Epoch 370/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 17.7937 - mean_absolute_error: 17.7937 - val_loss: 371.5257 - val_mean_absolute_error: 371.5257\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 370.36471\n",
      "Epoch 371/500\n",
      "912/912 [==============================] - 0s 263us/step - loss: 17.4391 - mean_absolute_error: 17.4391 - val_loss: 391.7730 - val_mean_absolute_error: 391.7730\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 370.36471\n",
      "Epoch 372/500\n",
      "912/912 [==============================] - 0s 277us/step - loss: 18.3978 - mean_absolute_error: 18.3978 - val_loss: 378.9945 - val_mean_absolute_error: 378.9945\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 370.36471\n",
      "Epoch 373/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 17.5869 - mean_absolute_error: 17.5869 - val_loss: 387.3386 - val_mean_absolute_error: 387.3386\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 370.36471\n",
      "Epoch 374/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.1785 - mean_absolute_error: 16.1785 - val_loss: 417.7435 - val_mean_absolute_error: 417.7435\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 370.36471\n",
      "Epoch 375/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 18.2300 - mean_absolute_error: 18.2300 - val_loss: 375.9245 - val_mean_absolute_error: 375.9246\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 370.36471\n",
      "Epoch 376/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.0714 - mean_absolute_error: 16.0714 - val_loss: 372.3632 - val_mean_absolute_error: 372.3632\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 370.36471\n",
      "Epoch 377/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 15.7968 - mean_absolute_error: 15.7968 - val_loss: 386.1947 - val_mean_absolute_error: 386.1947\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 370.36471\n",
      "Epoch 378/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 20.2799 - mean_absolute_error: 20.2799 - val_loss: 427.3418 - val_mean_absolute_error: 427.3418\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 370.36471\n",
      "Epoch 379/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 18.9453 - mean_absolute_error: 18.9453 - val_loss: 372.4752 - val_mean_absolute_error: 372.4752\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 370.36471\n",
      "Epoch 380/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 17.3899 - mean_absolute_error: 17.3899 - val_loss: 381.3643 - val_mean_absolute_error: 381.3643\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 370.36471\n",
      "Epoch 381/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.8876 - mean_absolute_error: 16.8876 - val_loss: 391.8285 - val_mean_absolute_error: 391.8285\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 370.36471\n",
      "Epoch 382/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 18.8599 - mean_absolute_error: 18.8599 - val_loss: 396.5931 - val_mean_absolute_error: 396.5931\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 370.36471\n",
      "Epoch 383/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.5078 - mean_absolute_error: 16.5078 - val_loss: 376.7335 - val_mean_absolute_error: 376.7335\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 370.36471\n",
      "Epoch 384/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 17.8184 - mean_absolute_error: 17.8184 - val_loss: 374.9048 - val_mean_absolute_error: 374.9048\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 370.36471\n",
      "Epoch 385/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 16.6548 - mean_absolute_error: 16.6548 - val_loss: 378.1533 - val_mean_absolute_error: 378.1533\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 370.36471\n",
      "Epoch 386/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 16.1101 - mean_absolute_error: 16.1101 - val_loss: 383.1334 - val_mean_absolute_error: 383.1334\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 370.36471\n",
      "Epoch 387/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.2537 - mean_absolute_error: 16.2537 - val_loss: 373.8953 - val_mean_absolute_error: 373.8953\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 370.36471\n",
      "Epoch 388/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 15.2461 - mean_absolute_error: 15.2461 - val_loss: 379.6317 - val_mean_absolute_error: 379.6317\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 370.36471\n",
      "Epoch 389/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 15.5442 - mean_absolute_error: 15.5442 - val_loss: 427.5779 - val_mean_absolute_error: 427.5779\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 370.36471\n",
      "Epoch 390/500\n",
      "912/912 [==============================] - 0s 306us/step - loss: 17.2391 - mean_absolute_error: 17.2391 - val_loss: 375.3543 - val_mean_absolute_error: 375.3542\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 370.36471\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 0s 314us/step - loss: 16.4163 - mean_absolute_error: 16.4163 - val_loss: 421.9614 - val_mean_absolute_error: 421.9614\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 370.36471\n",
      "Epoch 392/500\n",
      "912/912 [==============================] - 0s 321us/step - loss: 15.9333 - mean_absolute_error: 15.9333 - val_loss: 447.2748 - val_mean_absolute_error: 447.2747\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 370.36471\n",
      "Epoch 393/500\n",
      "912/912 [==============================] - 0s 323us/step - loss: 19.4455 - mean_absolute_error: 19.4455 - val_loss: 395.5838 - val_mean_absolute_error: 395.5839\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 370.36471\n",
      "Epoch 394/500\n",
      "912/912 [==============================] - 0s 318us/step - loss: 15.7157 - mean_absolute_error: 15.7157 - val_loss: 373.7050 - val_mean_absolute_error: 373.7050\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 370.36471\n",
      "Epoch 395/500\n",
      "912/912 [==============================] - 0s 326us/step - loss: 15.0836 - mean_absolute_error: 15.0836 - val_loss: 378.7885 - val_mean_absolute_error: 378.7885\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 370.36471\n",
      "Epoch 396/500\n",
      "912/912 [==============================] - 0s 317us/step - loss: 17.3451 - mean_absolute_error: 17.3451 - val_loss: 389.4009 - val_mean_absolute_error: 389.4009\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 370.36471\n",
      "Epoch 397/500\n",
      "912/912 [==============================] - 0s 322us/step - loss: 18.4750 - mean_absolute_error: 18.4750 - val_loss: 394.4926 - val_mean_absolute_error: 394.4927\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 370.36471\n",
      "Epoch 398/500\n",
      "912/912 [==============================] - 0s 321us/step - loss: 16.5034 - mean_absolute_error: 16.5034 - val_loss: 382.1808 - val_mean_absolute_error: 382.1808\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 370.36471\n",
      "Epoch 399/500\n",
      "912/912 [==============================] - 0s 326us/step - loss: 15.5071 - mean_absolute_error: 15.5071 - val_loss: 387.0926 - val_mean_absolute_error: 387.0927\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 370.36471\n",
      "Epoch 400/500\n",
      "912/912 [==============================] - 0s 326us/step - loss: 17.3566 - mean_absolute_error: 17.3566 - val_loss: 389.0101 - val_mean_absolute_error: 389.0102\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 370.36471\n",
      "Epoch 401/500\n",
      "912/912 [==============================] - 0s 316us/step - loss: 16.5744 - mean_absolute_error: 16.5744 - val_loss: 376.5523 - val_mean_absolute_error: 376.5523\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 370.36471\n",
      "Epoch 402/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.4429 - mean_absolute_error: 16.4429 - val_loss: 371.8273 - val_mean_absolute_error: 371.8272\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 370.36471\n",
      "Epoch 403/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 15.6360 - mean_absolute_error: 15.6360 - val_loss: 372.8580 - val_mean_absolute_error: 372.8580\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 370.36471\n",
      "Epoch 404/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 20.8328 - mean_absolute_error: 20.8328 - val_loss: 407.2756 - val_mean_absolute_error: 407.2756\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 370.36471\n",
      "Epoch 405/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 18.9456 - mean_absolute_error: 18.9456 - val_loss: 473.8015 - val_mean_absolute_error: 473.8015\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 370.36471\n",
      "Epoch 406/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 18.3153 - mean_absolute_error: 18.3153 - val_loss: 408.6715 - val_mean_absolute_error: 408.6715\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 370.36471\n",
      "Epoch 407/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 18.0361 - mean_absolute_error: 18.0361 - val_loss: 379.7725 - val_mean_absolute_error: 379.7725\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 370.36471\n",
      "Epoch 408/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 17.9304 - mean_absolute_error: 17.9304 - val_loss: 370.9962 - val_mean_absolute_error: 370.9962\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 370.36471\n",
      "Epoch 409/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 14.9074 - mean_absolute_error: 14.9074 - val_loss: 375.5717 - val_mean_absolute_error: 375.5717\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 370.36471\n",
      "Epoch 410/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 15.6494 - mean_absolute_error: 15.6494 - val_loss: 394.7090 - val_mean_absolute_error: 394.7090\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 370.36471\n",
      "Epoch 411/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 19.0294 - mean_absolute_error: 19.0294 - val_loss: 410.5958 - val_mean_absolute_error: 410.5958\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 370.36471\n",
      "Epoch 412/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 19.4103 - mean_absolute_error: 19.4103 - val_loss: 373.6114 - val_mean_absolute_error: 373.6114\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 370.36471\n",
      "Epoch 413/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.1782 - mean_absolute_error: 17.1782 - val_loss: 373.1912 - val_mean_absolute_error: 373.1912\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 370.36471\n",
      "Epoch 414/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 20.0906 - mean_absolute_error: 20.0906 - val_loss: 393.7013 - val_mean_absolute_error: 393.7013\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 370.36471\n",
      "Epoch 415/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 16.5476 - mean_absolute_error: 16.5476 - val_loss: 374.2406 - val_mean_absolute_error: 374.2406\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 370.36471\n",
      "Epoch 416/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.8949 - mean_absolute_error: 15.8949 - val_loss: 371.6868 - val_mean_absolute_error: 371.6868\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 370.36471\n",
      "Epoch 417/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.9326 - mean_absolute_error: 16.9326 - val_loss: 372.6634 - val_mean_absolute_error: 372.6635\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 370.36471\n",
      "Epoch 418/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 16.0210 - mean_absolute_error: 16.0210 - val_loss: 383.3372 - val_mean_absolute_error: 383.3372\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 370.36471\n",
      "Epoch 419/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 18.3330 - mean_absolute_error: 18.3330 - val_loss: 464.7379 - val_mean_absolute_error: 464.7379\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 370.36471\n",
      "Epoch 420/500\n",
      "912/912 [==============================] - 0s 277us/step - loss: 17.6176 - mean_absolute_error: 17.6176 - val_loss: 389.9108 - val_mean_absolute_error: 389.9109\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 370.36471\n",
      "Epoch 421/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 19.1620 - mean_absolute_error: 19.1620 - val_loss: 415.5203 - val_mean_absolute_error: 415.5203\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 370.36471\n",
      "Epoch 422/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 18.9057 - mean_absolute_error: 18.9057 - val_loss: 434.0127 - val_mean_absolute_error: 434.0128\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 370.36471\n",
      "Epoch 423/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 19.1031 - mean_absolute_error: 19.1031 - val_loss: 432.2541 - val_mean_absolute_error: 432.2541\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 370.36471\n",
      "Epoch 424/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 17.6561 - mean_absolute_error: 17.6561 - val_loss: 377.3553 - val_mean_absolute_error: 377.3553\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 370.36471\n",
      "Epoch 425/500\n",
      "912/912 [==============================] - 0s 277us/step - loss: 16.1848 - mean_absolute_error: 16.1848 - val_loss: 422.5168 - val_mean_absolute_error: 422.5168\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 370.36471\n",
      "Epoch 426/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 17.9953 - mean_absolute_error: 17.9953 - val_loss: 383.9850 - val_mean_absolute_error: 383.9850\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 370.36471\n",
      "Epoch 427/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 0s 272us/step - loss: 15.8978 - mean_absolute_error: 15.8978 - val_loss: 411.5492 - val_mean_absolute_error: 411.5492\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 370.36471\n",
      "Epoch 428/500\n",
      "912/912 [==============================] - 0s 262us/step - loss: 15.9385 - mean_absolute_error: 15.9385 - val_loss: 411.2567 - val_mean_absolute_error: 411.2567\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 370.36471\n",
      "Epoch 429/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 22.1985 - mean_absolute_error: 22.1985 - val_loss: 417.0673 - val_mean_absolute_error: 417.0673\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 370.36471\n",
      "Epoch 430/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 17.3508 - mean_absolute_error: 17.3508 - val_loss: 382.9230 - val_mean_absolute_error: 382.9230\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 370.36471\n",
      "Epoch 431/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 16.2617 - mean_absolute_error: 16.2617 - val_loss: 373.5472 - val_mean_absolute_error: 373.5472\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 370.36471\n",
      "Epoch 432/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 15.7173 - mean_absolute_error: 15.7173 - val_loss: 380.2768 - val_mean_absolute_error: 380.2768\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 370.36471\n",
      "Epoch 433/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 17.1406 - mean_absolute_error: 17.1406 - val_loss: 383.7318 - val_mean_absolute_error: 383.7318\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 370.36471\n",
      "Epoch 434/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 16.4318 - mean_absolute_error: 16.4318 - val_loss: 383.5431 - val_mean_absolute_error: 383.5431\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 370.36471\n",
      "Epoch 435/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 16.7906 - mean_absolute_error: 16.7906 - val_loss: 443.3660 - val_mean_absolute_error: 443.3661\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 370.36471\n",
      "Epoch 436/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 21.0134 - mean_absolute_error: 21.0134 - val_loss: 398.5618 - val_mean_absolute_error: 398.5617\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 370.36471\n",
      "Epoch 437/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 17.0162 - mean_absolute_error: 17.0162 - val_loss: 374.9752 - val_mean_absolute_error: 374.9752\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 370.36471\n",
      "Epoch 438/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.2010 - mean_absolute_error: 16.2010 - val_loss: 372.4644 - val_mean_absolute_error: 372.4644\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 370.36471\n",
      "Epoch 439/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 19.0541 - mean_absolute_error: 19.0541 - val_loss: 421.9365 - val_mean_absolute_error: 421.9366\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 370.36471\n",
      "Epoch 440/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 18.9987 - mean_absolute_error: 18.9987 - val_loss: 387.7470 - val_mean_absolute_error: 387.7470\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 370.36471\n",
      "Epoch 441/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.1637 - mean_absolute_error: 16.1637 - val_loss: 373.7583 - val_mean_absolute_error: 373.7584\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 370.36471\n",
      "Epoch 442/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.9787 - mean_absolute_error: 15.9786 - val_loss: 429.9237 - val_mean_absolute_error: 429.9237\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 370.36471\n",
      "Epoch 443/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.0117 - mean_absolute_error: 17.0117 - val_loss: 386.3433 - val_mean_absolute_error: 386.3433\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 370.36471\n",
      "Epoch 444/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.3429 - mean_absolute_error: 17.3429 - val_loss: 372.5806 - val_mean_absolute_error: 372.5807\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 370.36471\n",
      "Epoch 445/500\n",
      "912/912 [==============================] - 0s 276us/step - loss: 16.0936 - mean_absolute_error: 16.0936 - val_loss: 376.4055 - val_mean_absolute_error: 376.4055\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 370.36471\n",
      "Epoch 446/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.6353 - mean_absolute_error: 15.6353 - val_loss: 374.7982 - val_mean_absolute_error: 374.7982\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 370.36471\n",
      "Epoch 447/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 14.9115 - mean_absolute_error: 14.9115 - val_loss: 379.3122 - val_mean_absolute_error: 379.3122\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 370.36471\n",
      "Epoch 448/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 17.4303 - mean_absolute_error: 17.4303 - val_loss: 373.5429 - val_mean_absolute_error: 373.5429\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 370.36471\n",
      "Epoch 449/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 19.2524 - mean_absolute_error: 19.2524 - val_loss: 395.5255 - val_mean_absolute_error: 395.5255\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 370.36471\n",
      "Epoch 450/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 19.9959 - mean_absolute_error: 19.9959 - val_loss: 373.4368 - val_mean_absolute_error: 373.4368\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 370.36471\n",
      "Epoch 451/500\n",
      "912/912 [==============================] - 0s 272us/step - loss: 15.9121 - mean_absolute_error: 15.9121 - val_loss: 400.9123 - val_mean_absolute_error: 400.9123\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 370.36471\n",
      "Epoch 452/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 16.1960 - mean_absolute_error: 16.1961 - val_loss: 398.5164 - val_mean_absolute_error: 398.5164\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 370.36471\n",
      "Epoch 453/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.8238 - mean_absolute_error: 15.8238 - val_loss: 378.0710 - val_mean_absolute_error: 378.0710\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 370.36471\n",
      "Epoch 454/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.9925 - mean_absolute_error: 15.9925 - val_loss: 377.5653 - val_mean_absolute_error: 377.5653\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 370.36471\n",
      "Epoch 455/500\n",
      "912/912 [==============================] - 0s 269us/step - loss: 15.7311 - mean_absolute_error: 15.7311 - val_loss: 373.6493 - val_mean_absolute_error: 373.6493\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 370.36471\n",
      "Epoch 456/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.0083 - mean_absolute_error: 16.0083 - val_loss: 370.7350 - val_mean_absolute_error: 370.7350\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 370.36471\n",
      "Epoch 457/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 16.9293 - mean_absolute_error: 16.9293 - val_loss: 376.8604 - val_mean_absolute_error: 376.8603\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 370.36471\n",
      "Epoch 458/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 19.2629 - mean_absolute_error: 19.2629 - val_loss: 385.5449 - val_mean_absolute_error: 385.5450\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 370.36471\n",
      "Epoch 459/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 20.1280 - mean_absolute_error: 20.1280 - val_loss: 380.6295 - val_mean_absolute_error: 380.6295\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 370.36471\n",
      "Epoch 460/500\n",
      "912/912 [==============================] - 0s 288us/step - loss: 16.0693 - mean_absolute_error: 16.0693 - val_loss: 402.2170 - val_mean_absolute_error: 402.2170\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 370.36471\n",
      "Epoch 461/500\n",
      "912/912 [==============================] - 0s 277us/step - loss: 15.0967 - mean_absolute_error: 15.0967 - val_loss: 374.9363 - val_mean_absolute_error: 374.9363\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 370.36471\n",
      "Epoch 462/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 15.7251 - mean_absolute_error: 15.7251 - val_loss: 374.8225 - val_mean_absolute_error: 374.8225\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 370.36471\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 0s 270us/step - loss: 17.4179 - mean_absolute_error: 17.4179 - val_loss: 372.6794 - val_mean_absolute_error: 372.6794\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 370.36471\n",
      "Epoch 464/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 15.9810 - mean_absolute_error: 15.9810 - val_loss: 400.3451 - val_mean_absolute_error: 400.3451\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 370.36471\n",
      "Epoch 465/500\n",
      "912/912 [==============================] - 0s 278us/step - loss: 16.1362 - mean_absolute_error: 16.1362 - val_loss: 412.3501 - val_mean_absolute_error: 412.3501\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 370.36471\n",
      "Epoch 466/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 15.8970 - mean_absolute_error: 15.8970 - val_loss: 409.8622 - val_mean_absolute_error: 409.8622\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 370.36471\n",
      "Epoch 467/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 17.6573 - mean_absolute_error: 17.6573 - val_loss: 421.1237 - val_mean_absolute_error: 421.1236\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 370.36471\n",
      "Epoch 468/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 21.5825 - mean_absolute_error: 21.5825 - val_loss: 434.1306 - val_mean_absolute_error: 434.1306\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 370.36471\n",
      "Epoch 469/500\n",
      "912/912 [==============================] - 0s 262us/step - loss: 18.9410 - mean_absolute_error: 18.9410 - val_loss: 371.9525 - val_mean_absolute_error: 371.9525\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 370.36471\n",
      "Epoch 470/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.8281 - mean_absolute_error: 15.8281 - val_loss: 382.1096 - val_mean_absolute_error: 382.1096\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 370.36471\n",
      "Epoch 471/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.6973 - mean_absolute_error: 16.6973 - val_loss: 385.8591 - val_mean_absolute_error: 385.8591\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 370.36471\n",
      "Epoch 472/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 18.0211 - mean_absolute_error: 18.0211 - val_loss: 399.3355 - val_mean_absolute_error: 399.3354\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 370.36471\n",
      "Epoch 473/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 18.3656 - mean_absolute_error: 18.3656 - val_loss: 399.0122 - val_mean_absolute_error: 399.0122\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 370.36471\n",
      "Epoch 474/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 19.9667 - mean_absolute_error: 19.9667 - val_loss: 387.4848 - val_mean_absolute_error: 387.4848\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 370.36471\n",
      "Epoch 475/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 14.8699 - mean_absolute_error: 14.8699 - val_loss: 385.7787 - val_mean_absolute_error: 385.7787\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 370.36471\n",
      "Epoch 476/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 16.1097 - mean_absolute_error: 16.1097 - val_loss: 371.2893 - val_mean_absolute_error: 371.2893\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 370.36471\n",
      "Epoch 477/500\n",
      "912/912 [==============================] - 0s 266us/step - loss: 20.2656 - mean_absolute_error: 20.2656 - val_loss: 393.9003 - val_mean_absolute_error: 393.9003\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 370.36471\n",
      "Epoch 478/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 20.2008 - mean_absolute_error: 20.2008 - val_loss: 383.8199 - val_mean_absolute_error: 383.8199\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 370.36471\n",
      "Epoch 479/500\n",
      "912/912 [==============================] - 0s 273us/step - loss: 17.0116 - mean_absolute_error: 17.0116 - val_loss: 378.2271 - val_mean_absolute_error: 378.2271\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 370.36471\n",
      "Epoch 480/500\n",
      "912/912 [==============================] - 0s 288us/step - loss: 15.5241 - mean_absolute_error: 15.5241 - val_loss: 373.3802 - val_mean_absolute_error: 373.3802\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 370.36471\n",
      "Epoch 481/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.1550 - mean_absolute_error: 15.1550 - val_loss: 380.5118 - val_mean_absolute_error: 380.5118\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 370.36471\n",
      "Epoch 482/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.7982 - mean_absolute_error: 15.7983 - val_loss: 384.0634 - val_mean_absolute_error: 384.0634\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 370.36471\n",
      "Epoch 483/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 16.4283 - mean_absolute_error: 16.4283 - val_loss: 373.2199 - val_mean_absolute_error: 373.2199\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 370.36471\n",
      "Epoch 484/500\n",
      "912/912 [==============================] - 0s 292us/step - loss: 15.2354 - mean_absolute_error: 15.2354 - val_loss: 372.6914 - val_mean_absolute_error: 372.6913\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 370.36471\n",
      "Epoch 485/500\n",
      "912/912 [==============================] - 0s 274us/step - loss: 19.0231 - mean_absolute_error: 19.0231 - val_loss: 390.2633 - val_mean_absolute_error: 390.2633\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 370.36471\n",
      "Epoch 486/500\n",
      "912/912 [==============================] - 0s 313us/step - loss: 15.6194 - mean_absolute_error: 15.6194 - val_loss: 381.0592 - val_mean_absolute_error: 381.0592\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 370.36471\n",
      "Epoch 487/500\n",
      "912/912 [==============================] - 0s 287us/step - loss: 14.7955 - mean_absolute_error: 14.7955 - val_loss: 390.7973 - val_mean_absolute_error: 390.7973\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 370.36471\n",
      "Epoch 488/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 16.2282 - mean_absolute_error: 16.2282 - val_loss: 373.2261 - val_mean_absolute_error: 373.2261\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 370.36471\n",
      "Epoch 489/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.3617 - mean_absolute_error: 15.3617 - val_loss: 372.6365 - val_mean_absolute_error: 372.6365\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 370.36471\n",
      "Epoch 490/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.7631 - mean_absolute_error: 15.7631 - val_loss: 373.9470 - val_mean_absolute_error: 373.9470\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 370.36471\n",
      "Epoch 491/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.3629 - mean_absolute_error: 15.3629 - val_loss: 378.2708 - val_mean_absolute_error: 378.2708\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 370.36471\n",
      "Epoch 492/500\n",
      "912/912 [==============================] - 0s 270us/step - loss: 15.1959 - mean_absolute_error: 15.1959 - val_loss: 436.0311 - val_mean_absolute_error: 436.0311\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 370.36471\n",
      "Epoch 493/500\n",
      "912/912 [==============================] - 0s 264us/step - loss: 15.4290 - mean_absolute_error: 15.4290 - val_loss: 370.9850 - val_mean_absolute_error: 370.9850\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 370.36471\n",
      "Epoch 494/500\n",
      "912/912 [==============================] - 0s 275us/step - loss: 15.0155 - mean_absolute_error: 15.0155 - val_loss: 396.4048 - val_mean_absolute_error: 396.4048\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 370.36471\n",
      "Epoch 495/500\n",
      "912/912 [==============================] - 0s 267us/step - loss: 15.8829 - mean_absolute_error: 15.8829 - val_loss: 372.7116 - val_mean_absolute_error: 372.7116\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 370.36471\n",
      "Epoch 496/500\n",
      "912/912 [==============================] - 0s 265us/step - loss: 15.4853 - mean_absolute_error: 15.4853 - val_loss: 377.3486 - val_mean_absolute_error: 377.3486\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 370.36471\n",
      "Epoch 497/500\n",
      "912/912 [==============================] - 0s 268us/step - loss: 15.0495 - mean_absolute_error: 15.0495 - val_loss: 386.0692 - val_mean_absolute_error: 386.0692\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 370.36471\n",
      "Epoch 498/500\n",
      "912/912 [==============================] - 0s 271us/step - loss: 17.1683 - mean_absolute_error: 17.1683 - val_loss: 378.5015 - val_mean_absolute_error: 378.5015\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 370.36471\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 0s 269us/step - loss: 19.6977 - mean_absolute_error: 19.6977 - val_loss: 380.2891 - val_mean_absolute_error: 380.2891\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 370.36471\n",
      "Epoch 500/500\n",
      "912/912 [==============================] - 0s 286us/step - loss: 15.9194 - mean_absolute_error: 15.9194 - val_loss: 382.5516 - val_mean_absolute_error: 382.5516\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 370.36471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b790e3fd48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(trainX, trainY, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes = NN_model.predict(testX)\n",
    "testY = testY.reshape(560,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.90129477530718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0987052246928215"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erroEmPorcento = mean_absolute_percentage_error(testY,predicoes)\n",
    "print(100-erroEmPorcento)\n",
    "erroEmPorcento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.DataFrame(testY,columns=['Esperado'])\n",
    "resultado['Predito'] = predicoes\n",
    "resultado.index = data.tail(560).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN\n",
      "MAPE: 96.901\n",
      "Desvio: -3.099\n",
      "MSE: 109995.469\n",
      "RMSE: 331.656\n",
      "MAE: 222.061\n",
      "MSLE: 0.002\n",
      "R2 score: 98.024\n",
      "Explaine Variance Score: 98.319\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('DNN')\n",
    "print(\"MAPE: %.3f\"%(100-mean_absolute_percentage_error(testY,predicoes)))\n",
    "print(\"Desvio: %.3f\"%-mean_absolute_percentage_error(testY,predicoes))\n",
    "print(\"MSE: %.3f\"%mean_squared_error(testY,predicoes))\n",
    "print(\"RMSE: %.3f\"%sqrt(mean_squared_error(testY,predicoes)))\n",
    "print(\"MAE: %.3f\"%mean_absolute_error(testY,predicoes))\n",
    "print(\"MSLE: %.3f\"%mean_squared_log_error(testY,predicoes))\n",
    "print(\"R2 score: %.3f\"%(r2_score(testY,predicoes)*100))\n",
    "print(\"Explaine Variance Score: %.3f\"%(explained_variance_score(testY,predicoes)*100))\n",
    "resultado.plot()\n",
    "plt.xticks(rotation=20)\n",
    "plt.title('DNN')\n",
    "plt.savefig('DNN_teste.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predio de um dia em especifico\n",
      "MAPE: 96.191\n",
      "Desvio: 3.809\n",
      "RMSE: 282.771\n",
      "Fechamento [7424.29]\n",
      "Predito [[7707.061]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparao do FechamentoXPredio')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "entrada = np.array([[7463.11,7761.24,7569.63]])\n",
    "fechamentohoje = [7424.29]\n",
    "predicaohoje = NN_model.predict(entrada)\n",
    "print(\"Predio de um dia em especifico\")\n",
    "print(\"MAPE: %.3f\"%(100-mean_absolute_percentage_error(fechamentohoje,predicaohoje)))\n",
    "print(\"Desvio: %.3f\"%mean_absolute_percentage_error(fechamentohoje,predicaohoje))\n",
    "print(\"RMSE: %.3f\"%sqrt(mean_squared_error(fechamentohoje,predicaohoje)))\n",
    "print(\"Fechamento %s\"%fechamentohoje)\n",
    "print(\"Predito %s\"%predicaohoje)\n",
    "\n",
    "vetorgrafico = { \"Predio\": predicaohoje[0] , \"Fechamento hoje\": fechamentohoje[0]}\n",
    "colunas = [i for i in vetorgrafico.keys()]\n",
    "valor = [j for j in vetorgrafico.values()]\n",
    "popPos = np.arange(len(colunas))\n",
    "plt.barh(popPos, valor, align='center', color='blue')\n",
    "plt.yticks(popPos, colunas)\n",
    "plt.xlabel('Valores')\n",
    "plt.title('Comparao do FechamentoXPredio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
